{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c91c2d5b-205c-4bf1-8d7f-7b5b877e1b58",
   "metadata": {},
   "source": [
    "# Task 1 - Zero Shot Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee6016-6020-4d53-b859-369781fb51d2",
   "metadata": {},
   "source": [
    "### Load OpenAI API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9726e81b-acaf-45bb-984d-aa00a0ec7dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your openai API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "gemini_key = getpass(\"Enter your openai API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c684a5-35b8-4997-ada5-220ba49eea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=gemini_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6525236-c8c8-40b7-8bf2-1609579d4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f377fb0-49c5-4320-ac8c-3fe5fa64cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gemini-1.5-flash\"):\n",
    "    model = genai.GenerativeModel(model, generation_config=genai.GenerationConfig(temperature=0,))\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10bd1c8-afac-4942-906c-92cd882dd4ec",
   "metadata": {},
   "source": [
    "### Let's try out the ChatGPT API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0936bb5-9c60-41a4-a973-678af2345fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edd00828-afee-4214-9451-3c1d56094b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Decision Trees: A Simple Yet Powerful Machine Learning Algorithm\n",
       "\n",
       "Decision trees are a fundamental and widely used algorithm in machine learning.  Their intuitive nature and ease of interpretation make them a great starting point for understanding predictive modeling, while their ability to handle both classification and regression tasks makes them incredibly versatile.  This blog post will explore the core concepts behind decision trees, their strengths and weaknesses, and some common applications.\n",
       "\n",
       "**What is a Decision Tree?**\n",
       "\n",
       "Imagine a flowchart where each node represents a decision based on a feature, each branch represents the outcome of that decision, and each leaf node represents a final prediction. That's essentially a decision tree.  The algorithm works by recursively partitioning the data based on the features that best separate the different classes (in classification) or predict the target variable (in regression).\n",
       "\n",
       "**How does it work?**\n",
       "\n",
       "The process of building a decision tree involves several key steps:\n",
       "\n",
       "1. **Root Node Selection:** The algorithm starts with the root node, which represents the entire dataset.  It then selects the best feature to split the data based on a metric like Gini impurity (for classification) or mean squared error (for regression).  The \"best\" feature is the one that results in the most homogeneous subsets after splitting.\n",
       "\n",
       "2. **Recursive Partitioning:**  The process repeats recursively for each subset created by the split.  The algorithm continues to select the best feature to split each subset until a stopping criterion is met (e.g., a maximum depth is reached, or the nodes become sufficiently pure).\n",
       "\n",
       "3. **Leaf Node Assignment:** Once the recursive partitioning is complete, each leaf node is assigned a class label (in classification) or a predicted value (in regression).  This is typically done by assigning the majority class or the average value of the target variable within that leaf node.\n",
       "\n",
       "**Key Concepts:**\n",
       "\n",
       "* **Gini Impurity:** Measures the probability of incorrectly classifying a randomly chosen element from the dataset if it were randomly labeled according to the class distribution in the subset. Lower Gini impurity indicates better separation.\n",
       "\n",
       "* **Information Gain:** Measures the reduction in entropy (uncertainty) achieved by splitting the data on a particular feature.  Higher information gain indicates a better split.\n",
       "\n",
       "* **Pruning:** A technique used to prevent overfitting.  It involves removing branches of the tree that don't significantly improve the model's performance on unseen data.\n",
       "\n",
       "* **Overfitting:** A common problem where the tree becomes too complex and learns the training data too well, resulting in poor generalization to new data.\n",
       "\n",
       "**Strengths of Decision Trees:**\n",
       "\n",
       "* **Easy to understand and interpret:** The tree structure is visually intuitive and easy to explain to non-technical audiences.\n",
       "* **Handles both categorical and numerical data:**  Can be easily adapted to different data types.\n",
       "* **Requires little data preprocessing:**  Doesn't require extensive feature scaling or normalization.\n",
       "* **Can handle non-linear relationships:**  Can capture complex interactions between features.\n",
       "\n",
       "**Weaknesses of Decision Trees:**\n",
       "\n",
       "* **Prone to overfitting:**  Can create overly complex trees that don't generalize well.\n",
       "* **Sensitive to small changes in data:**  Slight variations in the training data can lead to significantly different trees.\n",
       "* **Can be unstable:**  The structure of the tree can change dramatically with small changes in the data.\n",
       "* **Bias towards features with many levels:**  May favor features with more distinct values.\n",
       "\n",
       "\n",
       "**Applications of Decision Trees:**\n",
       "\n",
       "Decision trees are used in a wide range of applications, including:\n",
       "\n",
       "* **Medical diagnosis:** Predicting diseases based on patient symptoms.\n",
       "* **Credit risk assessment:** Evaluating the creditworthiness of loan applicants.\n",
       "* **Customer churn prediction:** Identifying customers likely to cancel their subscriptions.\n",
       "* **Fraud detection:** Detecting fraudulent transactions.\n",
       "* **Image recognition:** Classifying images based on their features.\n",
       "\n",
       "\n",
       "**Conclusion:**\n",
       "\n",
       "Decision trees are a powerful and versatile machine learning algorithm with many advantages.  While they have some limitations, techniques like pruning and ensemble methods (like Random Forests and Gradient Boosting) can mitigate these weaknesses.  Understanding decision trees is a crucial step in mastering the broader field of machine learning.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = get_completion(prompt=\"Write a blog about DecisionTree\", model=\"gemini-1.5-flash\")\n",
    "display(Markdown(response))                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c02dc485-eac0-4b07-a82c-e74aeb2162e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Understanding Decision Trees: A Comprehensive Guide\n",
      "\n",
      "In the realm of machine learning and data science, decision trees stand out as one of the most intuitive and widely used algorithms. Their simplicity, interpretability, and effectiveness make them a popular choice for both beginners and seasoned professionals. In this blog, we will explore what decision trees are, how they work, their advantages and disadvantages, and some practical applications.\n",
      "\n",
      "## What is a Decision Tree?\n",
      "\n",
      "A decision tree is a flowchart-like structure used for classification and regression tasks. It consists of nodes that represent features (or attributes) of the data, branches that represent decision rules, and leaves that represent outcomes (or target values). The tree is built by splitting the data into subsets based on the value of the features, ultimately leading to a decision or prediction.\n",
      "\n",
      "### Structure of a Decision Tree\n",
      "\n",
      "1. **Root Node**: The top node of the tree, representing the entire dataset.\n",
      "2. **Decision Nodes**: Nodes that split the data based on certain conditions.\n",
      "3. **Leaf Nodes**: Terminal nodes that provide the final output or prediction.\n",
      "4. **Branches**: The connections between nodes that represent the flow of decisions.\n",
      "\n",
      "## How Decision Trees Work\n",
      "\n",
      "The process of building a decision tree involves several steps:\n",
      "\n",
      "1. **Selecting the Best Feature**: The algorithm evaluates all features and selects the one that best separates the data into distinct classes. Common criteria for this selection include:\n",
      "   - **Gini Impurity**: Measures the impurity of a dataset. A lower Gini score indicates a better split.\n",
      "   - **Entropy**: Measures the amount of disorder or uncertainty in the dataset. The goal is to minimize entropy after the split.\n",
      "   - **Mean Squared Error (MSE)**: Used for regression tasks to minimize the variance in the target variable.\n",
      "\n",
      "2. **Splitting the Data**: Once the best feature is selected, the data is split into subsets based on the feature's values.\n",
      "\n",
      "3. **Recursion**: The process is repeated for each subset, creating new decision nodes until a stopping criterion is met (e.g., maximum depth, minimum samples per leaf, or no further improvement).\n",
      "\n",
      "4. **Pruning**: To avoid overfitting, the tree may be pruned by removing nodes that provide little predictive power.\n",
      "\n",
      "## Advantages of Decision Trees\n",
      "\n",
      "- **Interpretability**: Decision trees are easy to understand and visualize, making them accessible for non-technical stakeholders.\n",
      "- **No Need for Feature Scaling**: Unlike algorithms such as SVM or K-means, decision trees do not require normalization or standardization of features.\n",
      "- **Handles Both Numerical and Categorical Data**: Decision trees can work with various data types without the need for extensive preprocessing.\n",
      "- **Robust to Outliers**: Decision trees are less sensitive to outliers compared to other algorithms.\n",
      "\n",
      "## Disadvantages of Decision Trees\n",
      "\n",
      "- **Overfitting**: Decision trees can easily become too complex, capturing noise in the data rather than the underlying pattern.\n",
      "- **Instability**: Small changes in the data can lead to different tree structures, making them less robust.\n",
      "- **Bias towards Dominant Classes**: In imbalanced datasets, decision trees may favor the majority class.\n",
      "\n",
      "## Practical Applications of Decision Trees\n",
      "\n",
      "Decision trees are versatile and can be applied in various domains, including:\n",
      "\n",
      "- **Healthcare**: Predicting patient outcomes based on medical history and symptoms.\n",
      "- **Finance**: Assessing credit risk and determining loan approvals.\n",
      "- **Marketing**: Segmenting customers based on purchasing behavior and preferences.\n",
      "- **Manufacturing**: Predicting equipment failures and optimizing maintenance schedules.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Decision trees are a powerful tool in the data scientist's toolkit, offering a blend of simplicity and effectiveness. While they have their limitations, understanding how to leverage decision trees can lead to valuable insights and predictions across various fields. As you delve deeper into machine learning, consider incorporating decision trees into your projects, and explore their potential to enhance your data-driven decision-making processes. \n",
      "\n",
      "Whether you're a beginner or an experienced practitioner, mastering decision trees can significantly enhance your analytical capabilities and help you tackle complex problems with confidence. Happy learning!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20776319-e0c8-47af-b7ca-9c3439dd65f3",
   "metadata": {},
   "source": [
    "# Task 1 - Zero-Shot Classification ( without providing any output examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b5b2382b-13a4-404d-8269-85c772431794",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    f\"\"\"\n",
    "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
    "    The sound quality is impressively clear with just the right amount of bass.\n",
    "    It's also waterproof, which tested true during a recent splashing incident.\n",
    "    Though it's compact, the volume can really fill the space.\n",
    "    The price was a bargain for such high-quality sound.\n",
    "    Shipping was also on point, arriving two days early in secure packaging.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Needed a new kitchen blender, but this model has been a nightmare.\n",
    "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
    "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
    "    I thought the brand meant quality, but this product has proven me wrong.\n",
    "    Plus, it arrived three days late. Definitely not worth the expense.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf068770-41b5-4791-9fda-d6db4cdfedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = []\n",
    "\n",
    "for review in reviews:\n",
    "    prompt = f\"\"\"\n",
    "    Act as a product review analyst. Given the following review, display the overall sentiment for the review as only one of the following:\n",
    "    Positive, Negative OR Neutral\n",
    "\n",
    "    '''{review}'''\n",
    "    \"\"\"\n",
    "    responses = get_completion(prompt=prompt, model=\"gemini-1.5-flash\")\n",
    "    response.append(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "554b88f6-02a7-477d-a8a0-38be8c38d4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:  \n",
      "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
      "    The sound quality is impressively clear with just the right amount of bass.\n",
      "    It's also waterproof, which tested true during a recent splashing incident.\n",
      "    Though it's compact, the volume can really fill the space.\n",
      "    The price was a bargain for such high-quality sound.\n",
      "    Shipping was also on point, arriving two days early in secure packaging.\n",
      "    \n",
      "Sentiment : Positive\n",
      "\n",
      "***************************\n",
      "\n",
      "\n",
      "Review:  \n",
      "    Needed a new kitchen blender, but this model has been a nightmare.\n",
      "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
      "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
      "    I thought the brand meant quality, but this product has proven me wrong.\n",
      "    Plus, it arrived three days late. Definitely not worth the expense.\n",
      "    \n",
      "Sentiment : Negative\n",
      "\n",
      "***************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for review, response in zip(reviews, response):\n",
    "    print(\"Review: \", review)\n",
    "    print(\"Sentiment :\", response)\n",
    "    print(\"***************************\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e860e46-440e-43a1-a375-7672e3151ecd",
   "metadata": {},
   "source": [
    "# Task 2 - Few-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "14e8cc84-b19c-4192-93cd-6886facc6c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = []\n",
    "\n",
    "for review in reviews:\n",
    "    prompt = f\"\"\"\n",
    "              Act as a product review analyst.\n",
    "              Given the following review,\n",
    "              Display only the overall sentiment for the review:\n",
    "\n",
    "              Try to classify it by using the following examples as a reference:\n",
    "\n",
    "              Review: Just received the Laptop I ordered for work, and it's amazing.\n",
    "              Sentiment: 😊\n",
    "\n",
    "              Review: Needed a new mechanical keyboard, but this model has been totally disappointing.\n",
    "              Sentiment: 😡\n",
    "\n",
    "              Review: ```{review}```\n",
    "              \"\"\"\n",
    "    responses = get_completion(prompt=prompt, model=\"gemini-1.5-flash\")\n",
    "    response.append(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4c5f545-eb96-4b02-bf0e-925fe15ea105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['😊\\n', '😡\\n']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a079463-d729-4b5f-ab15-c240e69d76ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:  \n",
      "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
      "    The sound quality is impressively clear with just the right amount of bass.\n",
      "    It's also waterproof, which tested true during a recent splashing incident.\n",
      "    Though it's compact, the volume can really fill the space.\n",
      "    The price was a bargain for such high-quality sound.\n",
      "    Shipping was also on point, arriving two days early in secure packaging.\n",
      "    \n",
      "Sentiment : 😊\n",
      "\n",
      "***************************\n",
      "\n",
      "\n",
      "Review:  \n",
      "    Needed a new kitchen blender, but this model has been a nightmare.\n",
      "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
      "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
      "    I thought the brand meant quality, but this product has proven me wrong.\n",
      "    Plus, it arrived three days late. Definitely not worth the expense.\n",
      "    \n",
      "Sentiment : 😡\n",
      "\n",
      "***************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for review, response in zip(reviews, response):\n",
    "    print(\"Review: \", review)\n",
    "    print(\"Sentiment :\", response)\n",
    "    print(\"***************************\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68468f22-a777-44a0-ac3b-f4a97b1614d2",
   "metadata": {},
   "source": [
    "# Task 3 - Coding Tasks - Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a35d5a0b-55fc-453e-92de-c3bf654345d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "There's no readily available Python library specifically designed to interact with Google AI's Gemini model and directly implement \"chain of thought\" prompting in the way DeepSeek R1 might.  Gemini's API is still under development and its specifics aren't publicly documented in a way that allows for precise code generation.\n",
       "\n",
       "However, I can provide a Python framework that demonstrates the core concepts of chain-of-thought prompting, which you can adapt once Gemini's API becomes more accessible.  This example uses a hypothetical `gemini_api` function to represent the interaction with the Gemini model.  You'll need to replace this with the actual API calls when they become available.\n",
       "\n",
       "\n",
       "```python\n",
       "import json\n",
       "\n",
       "# Placeholder for the hypothetical Gemini API call.  REPLACE THIS with actual API calls.\n",
       "def gemini_api(prompt, model=\"gemini-pro\"): #Example model name, replace as needed\n",
       "    \"\"\"\n",
       "    Sends a prompt to the Gemini API and returns the response.\n",
       "\n",
       "    Args:\n",
       "        prompt: The prompt string.\n",
       "        model: The Gemini model to use (e.g., \"gemini-pro\", \"gemini-ultra\").\n",
       "\n",
       "    Returns:\n",
       "        A dictionary containing the API response, or None if there's an error.\n",
       "    \"\"\"\n",
       "    try:\n",
       "        # Simulate API call - REPLACE THIS with actual API interaction\n",
       "        # ... your Gemini API call code here ...\n",
       "        # Example simulated response:\n",
       "        if prompt.lower().startswith(\"what is\"):\n",
       "            return {\"response\": \"This is a simulated Gemini response.\"}\n",
       "        else:\n",
       "            return {\"response\": \"Another simulated response.\"}\n",
       "\n",
       "    except Exception as e:\n",
       "        print(f\"Error calling Gemini API: {e}\")\n",
       "        return None\n",
       "\n",
       "\n",
       "def chain_of_thought_prompting(question, intermediate_steps=3):\n",
       "    \"\"\"\n",
       "    Generates a chain-of-thought prompt and sends it to the Gemini API.\n",
       "\n",
       "    Args:\n",
       "        question: The question to answer.\n",
       "        intermediate_steps: The number of intermediate reasoning steps to include.\n",
       "\n",
       "    Returns:\n",
       "        The Gemini API's response, or None if there's an error.\n",
       "    \"\"\"\n",
       "\n",
       "    prompt = f\"Let's think step by step to answer this question: {question}\\n\\n\"\n",
       "    for i in range(intermediate_steps):\n",
       "        prompt += f\"Step {i+1}: \"\n",
       "\n",
       "    prompt += \"\\nFinal Answer:\"\n",
       "\n",
       "    response = gemini_api(prompt)\n",
       "    if response:\n",
       "        return response[\"response\"]\n",
       "    else:\n",
       "        return None\n",
       "\n",
       "\n",
       "# Example usage:\n",
       "question = \"What is the capital of France?\"\n",
       "answer = chain_of_thought_prompting(question, intermediate_steps=2)\n",
       "print(f\"Question: {question}\")\n",
       "print(f\"Answer: {answer}\")\n",
       "\n",
       "\n",
       "question = \"If a train leaves Chicago at 8 am traveling at 60 mph and another train leaves New York at 9 am traveling at 70 mph, when will they meet?\" #Example requiring more steps\n",
       "answer = chain_of_thought_prompting(question, intermediate_steps=5)\n",
       "print(f\"Question: {question}\")\n",
       "print(f\"Answer: {answer}\")\n",
       "\n",
       "```\n",
       "\n",
       "Remember to replace the placeholder `gemini_api` function with the actual Gemini API calls once the API is publicly available and documented.  You'll also need to adapt the prompt engineering to best suit the Gemini model's capabilities.  The success of chain-of-thought prompting heavily relies on the quality and structure of your prompts.  Experimentation will be key.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt =f\"\"\"\n",
    "Act as an expert in generating python code.\n",
    "\n",
    "Your task is to generate python code to build a \"chain of thought\" prompt pattern how deep seek r1 using\n",
    "by googleai with gemini model by python library\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gemini-1.5-flash\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2a1e27b-8828-4b43-8afa-e905adcd5cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Google GenAI library doesn't directly offer a pre-built logistic regression model.  Instead, we'll use scikit-learn, a widely used and powerful machine learning library in Python, to build and train a logistic regression model for the Titanic dataset.  This solution will be robust, efficient, and clearly commented.\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.linear_model import LogisticRegression\n",
       "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
       "from sklearn.compose import ColumnTransformer\n",
       "from sklearn.pipeline import Pipeline\n",
       "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
       "\n",
       "# Load the Titanic dataset (replace 'titanic.csv' with your actual file path)\n",
       "try:\n",
       "    df = pd.read_csv('titanic.csv')\n",
       "except FileNotFoundError:\n",
       "    print(\"Error: titanic.csv not found. Please ensure the file is in the same directory.\")\n",
       "    exit()\n",
       "\n",
       "\n",
       "# Data Preprocessing\n",
       "# 1. Handle Missing Values:  Simple imputation for demonstration.  More sophisticated methods could be used.\n",
       "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
       "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
       "\n",
       "\n",
       "# 2. Feature Engineering: Create a 'FamilySize' feature\n",
       "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
       "\n",
       "\n",
       "# 3. Feature Selection: Drop irrelevant columns\n",
       "df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
       "\n",
       "\n",
       "# 4. One-Hot Encoding for Categorical Features\n",
       "categorical_features = ['Sex', 'Embarked']\n",
       "numerical_features = ['Age', 'SibSp', 'Parch', 'Fare', 'FamilySize']\n",
       "\n",
       "preprocessor = ColumnTransformer(\n",
       "    transformers=[\n",
       "        ('num', StandardScaler(), numerical_features),\n",
       "        ('cat', OneHotEncoder(), categorical_features)\n",
       "    ])\n",
       "\n",
       "\n",
       "# 5. Define features (X) and target (y)\n",
       "X = df.drop('Survived', axis=1)\n",
       "y = df['Survived']\n",
       "\n",
       "\n",
       "# 6. Split data into training and testing sets\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
       "\n",
       "\n",
       "# Build and Train the Logistic Regression Model\n",
       "model = Pipeline([\n",
       "    ('preprocessor', preprocessor),\n",
       "    ('classifier', LogisticRegression(max_iter=1000)) # Increased max_iter to ensure convergence\n",
       "])\n",
       "\n",
       "model.fit(X_train, y_train)\n",
       "\n",
       "\n",
       "# Make Predictions\n",
       "y_pred = model.predict(X_test)\n",
       "\n",
       "\n",
       "# Evaluate the Model\n",
       "accuracy = accuracy_score(y_test, y_pred)\n",
       "conf_matrix = confusion_matrix(y_test, y_pred)\n",
       "class_report = classification_report(y_test, y_pred)\n",
       "\n",
       "print(f\"Accuracy: {accuracy:.4f}\")\n",
       "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
       "print(\"\\nClassification Report:\\n\", class_report)\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "This improved code addresses missing values, performs feature engineering, uses a pipeline for cleaner code and better reproducibility, and provides a comprehensive evaluation of the model's performance. Remember to install the necessary libraries: `pandas`, `scikit-learn`.  You can do this using pip:  `pip install pandas scikit-learn`\n",
       "\n",
       "\n",
       "This example uses a simple imputation strategy for missing values. For a more robust solution, consider using more advanced techniques like KNN imputation or modeling the missingness mechanism.  Furthermore, hyperparameter tuning (e.g., using GridSearchCV) could improve model performance.  This example provides a solid foundation for building and evaluating a logistic regression model on the Titanic dataset.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt =f\"\"\"\n",
    "Act as an expert in generating python code.\n",
    "\n",
    "Your task is to generate python code to build a \"supervised maching learning by using Logistic Regression\" for\n",
    "Titanic Dataset by google genai python library\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gemini-1.5-flash\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01e09b75-5c50-4032-98e2-93e70348100d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This code uses scikit-learn for preprocessing and modeling, not the OpenAI library, as OpenAI doesn't directly provide tools for building and training MLPs.  Scikit-learn is a far more suitable and efficient library for this task.  OpenAI's capabilities are more focused on language models and related tasks.\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.impute import KNNImputer\n",
       "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
       "from sklearn.compose import ColumnTransformer\n",
       "from sklearn.pipeline import Pipeline\n",
       "from sklearn.neural_network import MLPClassifier\n",
       "from sklearn.metrics import classification_report, accuracy_score\n",
       "from sklearn.utils import resample\n",
       "\n",
       "\n",
       "# Load the Titanic dataset (replace 'titanic.csv' with your file path if needed)\n",
       "try:\n",
       "    df = pd.read_csv('titanic.csv')\n",
       "except FileNotFoundError:\n",
       "    print(\"Error: titanic.csv not found. Please ensure the file is in the same directory.\")\n",
       "    exit()\n",
       "\n",
       "\n",
       "# 1. Missing Value Treatment (KNN Imputation)\n",
       "knn_imputer = KNNImputer(n_neighbors=5)  # Adjust n_neighbors as needed\n",
       "numerical_cols = ['Age', 'Fare']\n",
       "df[numerical_cols] = knn_imputer.fit_transform(df[numerical_cols])\n",
       "\n",
       "\n",
       "# 2. Encoding Categorical Features\n",
       "categorical_cols = ['Sex', 'Embarked', 'Pclass']\n",
       "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), categorical_cols)], remainder='passthrough')\n",
       "df_encoded = ct.fit_transform(df)\n",
       "df_encoded = pd.DataFrame(df_encoded, columns=np.concatenate([ct.named_transformers_['encoder'].get_feature_names_out(categorical_cols), ['Survived','PassengerId','Name','Ticket','Cabin','SibSp','Parch']]))\n",
       "df_encoded = df_encoded.drop(['PassengerId','Name','Ticket','Cabin'],axis=1)\n",
       "\n",
       "\n",
       "# 3. Feature Scaling (Standardization)\n",
       "scaler = StandardScaler()\n",
       "numerical_cols_after_encoding = ['Age', 'Fare', 'SibSp', 'Parch']\n",
       "df_encoded[numerical_cols_after_encoding] = scaler.fit_transform(df_encoded[numerical_cols_after_encoding])\n",
       "\n",
       "\n",
       "# 4. Outlier Treatment (Simple capping -  replace with more sophisticated methods if needed)\n",
       "for col in numerical_cols_after_encoding:\n",
       "    upper_bound = df_encoded[col].quantile(0.95)\n",
       "    lower_bound = df_encoded[col].quantile(0.05)\n",
       "    df_encoded[col] = np.clip(df_encoded[col], lower_bound, upper_bound)\n",
       "\n",
       "\n",
       "# 5. Imbalance Treatment (Upsampling the minority class)\n",
       "df_majority = df_encoded[df_encoded['Survived'] == 0]\n",
       "df_minority = df_encoded[df_encoded['Survived'] == 1]\n",
       "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
       "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
       "\n",
       "\n",
       "# Separate features (X) and target (y)\n",
       "X = df_upsampled.drop('Survived', axis=1)\n",
       "y = df_upsampled['Survived'].astype(int)\n",
       "\n",
       "\n",
       "# Split data into training and testing sets\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
       "\n",
       "\n",
       "# Build and train the MLP model\n",
       "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42, early_stopping=True) # Adjust hyperparameters as needed\n",
       "mlp.fit(X_train, y_train)\n",
       "\n",
       "\n",
       "# Make predictions\n",
       "y_pred = mlp.predict(X_test)\n",
       "\n",
       "\n",
       "# Evaluate the model\n",
       "print(classification_report(y_test, y_pred))\n",
       "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
       "\n",
       "```\n",
       "\n",
       "Remember to install the necessary libraries: `pip install pandas scikit-learn numpy`\n",
       "\n",
       "This improved code addresses outliers with a simple capping method (consider more robust techniques like IQR or winsorization for better results), handles class imbalance using upsampling, and provides a more complete and robust solution.  Remember that hyperparameter tuning (e.g., using `GridSearchCV`) is crucial for optimal model performance.  The choice of `hidden_layer_sizes` in the `MLPClassifier` is arbitrary and should be optimized.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt =f\"\"\"\n",
    "Act as an expert in generating python code.\n",
    "\n",
    "Your task is to generate python code to build a \"supervised maching learning by using Deep Neural Network (MLP)\" for\n",
    "Titanic Dataset by openai python library.\n",
    "please note to do preprocessing extensively basis below instruction and post then build MultiLayer Perceptron Model-\n",
    "1) missing value treatement by using knn imputation\n",
    "2) encoding 3) Feature scaling 4) outlier treatement 5) imbalance treatement \n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gemini-1.5-flash\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d297e87-592e-4e89-8e7f-9a46829ff74e",
   "metadata": {},
   "source": [
    "# Task 4 - Coding Tasks - SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62c91270-cfdb-40ff-b53c-532ed36e14d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To retrieve the employee with the maximum salary in the 'IT' department, you can use a SQL query that joins the `employees`, `salaries`, and `departments` tables. Here’s how you can construct the query:\n",
       "\n",
       "```sql\n",
       "SELECT e.EmpID, e.EmpName, s.Salary\n",
       "FROM employees e\n",
       "JOIN salaries s ON e.EmpID = s.EmpID\n",
       "JOIN departments d ON e.DepName = d.DepName\n",
       "WHERE d.DepName = 'IT'\n",
       "ORDER BY s.Salary DESC\n",
       "LIMIT 1;\n",
       "```\n",
       "\n",
       "### Explanation:\n",
       "1. **SELECT**: We select the employee ID, employee name, and salary.\n",
       "2. **FROM**: We start from the `employees` table (aliased as `e`).\n",
       "3. **JOIN**: We join the `salaries` table (aliased as `s`) on the `EmpID` to get the salary information. We also join the `departments` table (aliased as `d`) on the `DepName` to filter by department.\n",
       "4. **WHERE**: We filter the results to only include employees in the 'IT' department.\n",
       "5. **ORDER BY**: We order the results by salary in descending order to get the highest salary first.\n",
       "6. **LIMIT 1**: We limit the results to just one record, which will be the employee with the maximum salary in the 'IT' department.\n",
       "\n",
       "This query will return the employee with the highest salary in the specified department."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as an expert in generating SQL code.\n",
    "\n",
    "understanding the following schema of the database tables carefully.\n",
    "Table departments, columns = [DepID, DepName]\n",
    "Table employees, columns = [EmpID, EmpName, DepName]\n",
    "Table salaries, columns = [EmpID, Salary]\n",
    "\n",
    "create a MySQL query for the employee with max salary in the 'IT' Department.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eddb293f-d52b-4aac-bc37-e12ab3090818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To create a Proc SQL query in SAS that retrieves the employee with the maximum salary in the 'IT' department, you can follow these steps:\n",
       "\n",
       "1. Join the `employees` table with the `salaries` table to get the salary information for each employee.\n",
       "2. Filter the results to include only those employees who belong to the 'IT' department.\n",
       "3. Use the `MAX` function to find the maximum salary and then retrieve the corresponding employee details.\n",
       "\n",
       "Here is the SAS Proc SQL code to achieve this:\n",
       "\n",
       "```sas\n",
       "proc sql;\n",
       "    select e.EmpID, e.EmpName, s.Salary\n",
       "    from employees e\n",
       "    join salaries s on e.EmpID = s.EmpID\n",
       "    where e.DepName = 'IT'\n",
       "    and s.Salary = (select max(Salary) \n",
       "                    from salaries s2 \n",
       "                    join employees e2 on s2.EmpID = e2.EmpID \n",
       "                    where e2.DepName = 'IT')\n",
       "    ;\n",
       "quit;\n",
       "```\n",
       "\n",
       "### Explanation:\n",
       "- The `select` statement retrieves the employee ID, employee name, and salary.\n",
       "- The `from` clause specifies the `employees` table (aliased as `e`) and joins it with the `salaries` table (aliased as `s`) on the `EmpID`.\n",
       "- The `where` clause filters the results to include only employees in the 'IT' department.\n",
       "- The subquery `(select max(Salary) ...)` finds the maximum salary for employees in the 'IT' department, ensuring that only the employee(s) with that maximum salary are returned.\n",
       "\n",
       "This query will return the employee(s) with the highest salary in the 'IT' department. If there are multiple employees with the same maximum salary, all of them will be included in the result."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as an expert in generating SQL code.\n",
    "\n",
    "understanding the following schema of the database tables carefully.\n",
    "Table departments, columns = [DepID, DepName]\n",
    "Table employees, columns = [EmpID, EmpName, DepName]\n",
    "Table salaries, columns = [EmpID, Salary]\n",
    "\n",
    "create a ProcSQL query in SAS for the employee with max salary in the 'IT' Department.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2ff51c-4947-4a6e-8dda-8025f353272e",
   "metadata": {},
   "source": [
    "# Task 5 - Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3645d6f1-39cc-47b8-84b2-927c690ffa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_note = \"\"\"\n",
    "60-year-old man in NAD with a h/o CAD, DM2, asthma, pharyngitis, SBP,\n",
    "and HTN on altace for 8 years awoke from sleep around 1:00 am this morning\n",
    "with a sore throat and swelling of the tongue.\n",
    "He came immediately to the ED because he was having difficulty swallowing and\n",
    "some trouble breathing due to obstruction caused by the swelling.\n",
    "He did not have any associated SOB, chest pain, itching, or nausea.\n",
    "He has not noticed any rashes.\n",
    "He says that he feels like it is swollen down in his esophagus as well.\n",
    "He does not recall vomiting but says he might have retched a bit.\n",
    "In the ED he was given 25mg benadryl IV, 125 mg solumedrol IV,\n",
    "and pepcid 20 mg IV.\n",
    "Family history of CHF and esophageal cancer (father).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "243ac82d-bdac-4c47-a3ac-cde4d5ffb94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the extracted information from the clinical note regarding symptoms:\n",
       "\n",
       "| Symptoms                                   | Present/Denies | Probability |\n",
       "|--------------------------------------------|----------------|-------------|\n",
       "| Sore throat                                | Present        | High        |\n",
       "| Swelling of the tongue                     | Present        | High        |\n",
       "| Difficulty swallowing                       | Present        | High        |\n",
       "| Trouble breathing                           | Present        | High        |\n",
       "| Shortness of breath                         | Denies         | High        |\n",
       "| Chest pain                                 | Denies         | High        |\n",
       "| Itching                                    | Denies         | High        |\n",
       "| Nausea                                     | Denies         | High        |\n",
       "| Rashes                                      | Denies         | High        |\n",
       "| Swelling in the esophagus                  | Present        | Medium      |\n",
       "| Vomiting                                   | Denies         | Medium      |\n",
       "| Retching                                   | Present        | Medium      |\n",
       "\n",
       "### Note on Probabilities:\n",
       "- **High Probability**: Symptoms such as sore throat, swelling of the tongue, difficulty swallowing, trouble breathing, and the absence of shortness of breath, chest pain, itching, nausea, and rashes are clearly stated in the clinical note. The language used is definitive, indicating a strong presence or absence of these symptoms.\n",
       "- **Medium Probability**: The swelling in the esophagus and retching are mentioned but are less definitive. The patient expresses a feeling of swelling in the esophagus, which is subjective and not directly observed. Retching is mentioned as a possibility rather than a certainty, leading to a medium probability rating.\n",
       "\n",
       "### Appendix Table\n",
       "\n",
       "| Acronym          | Expanded Form                     |\n",
       "|------------------|-----------------------------------|\n",
       "| NAD              | No Acute Distress                 |\n",
       "| h/o              | History of                        |\n",
       "| CAD              | Coronary Artery Disease           |\n",
       "| DM2              | Diabetes Mellitus Type 2         |\n",
       "| SBP              | Systolic Blood Pressure           |\n",
       "| HTN              | Hypertension                      |\n",
       "| IV               | Intravenous                       |\n",
       "| CHF              | Congestive Heart Failure          | \n",
       "| esophageal cancer | Esophageal Cancer                 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as an expert in analyzing and understanding clinical doctor notes in healthcare.\n",
    "Extract all symptoms only from the clinical note information below.\n",
    "Differentiate between symptoms that are present vs. absent.\n",
    "Give me the probability (high/ medium/ low) of how sure you are about the result.\n",
    "Add a note on the probabilities and why you think so.\n",
    "\n",
    "Output as a markdown table with the following columns,\n",
    "all symptoms should be expanded and no acronyms unless you don't know:\n",
    "\n",
    "Symptoms | Present/Denies | Probability.\n",
    "\n",
    "Also expand all acronyms.\n",
    "Output that also as a separate appendix table in Markdown.\n",
    "\n",
    "Clinical Note:\n",
    "```{clinical_note}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a95f25-fa94-4d40-aae6-3a9a2af41a99",
   "metadata": {},
   "source": [
    "# Task - 6 : Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db6b5c42-8419-4263-9d11-cd12b086db3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the translations of the provided text into the requested languages:\n",
       "\n",
       "**German:**\n",
       "Betreff: Antrag auf Krankheitsurlaub für [Urlaubsdaten]\n",
       "Sehr geehrter Manager,\n",
       "ich fühle mich unwohl und möchte für [Urlaubsdaten] Krankheitsurlaub beantragen. Ich werde sicherstellen, dass ich alle ausstehenden Aufgaben erledige, sobald ich zurück bin, und Sie informieren, falls es Änderungen gibt.\n",
       "Bitte lassen Sie mich wissen, ob Sie weitere Informationen benötigen.\n",
       "\n",
       "**Spanish:**\n",
       "Asunto: Solicitud de licencia por enfermedad del [Fechas de licencia]\n",
       "Estimado/a Gerente,\n",
       "me siento mal y me gustaría solicitar una licencia por enfermedad del [Fechas de licencia]. Me aseguraré de completar cualquier tarea pendiente una vez que regrese y le mantendré informado/a si hay algún cambio.\n",
       "Por favor, hágame saber si necesita más información.\n",
       "\n",
       "**Hindi:**\n",
       "विषय: [अवकाश तिथियों] पर बीमार छुट्टी के लिए अनुरोध\n",
       "प्रिय प्रबंधक,\n",
       "मैं अस्वस्थ महसूस कर रहा हूँ और [अवकाश तिथियों] के लिए बीमार छुट्टी का अनुरोध करना चाहता हूँ। मैं सुनिश्चित करूंगा कि लौटने के बाद कोई भी लंबित कार्य पूरा कर दूं और यदि कोई परिवर्तन होता है तो आपको अपडेट रखूंगा।\n",
       "कृपया मुझे बताएं कि क्या आपको किसी और जानकारी की आवश्यकता है।\n",
       "\n",
       "**Tamil:**\n",
       "หัวข้อ: [விடுமுறை தேதிகள்] இல் நோய்வாய்ப்பு விடுமுறை கோரிக்கை\n",
       "அன்புள்ள மேலாளர்,\n",
       "நான் உடல் நலக்குறைவால் பாதிக்கப்படுகிறேன் மற்றும் [விடுமுறை தேதிகள்] இல் நோய்வாய்ப்பு விடுமுறை கோர விரும்புகிறேன். நான் திரும்பிய பிறகு எந்தவொரு நிலுவையில் உள்ள பணிகளையும் முடிக்க உறுதி செய்கிறேன் மற்றும் எந்த மாற்றங்களும் இருந்தால் உங்களை புதுப்பிக்கிறேன்.\n",
       "மேலும் தகவலுக்கு நீங்கள் என்னை தொடர்பு கொள்ளவும்.\n",
       "\n",
       "**Telugu:**\n",
       "విషయం: [విడుదల తేదీలు] పై రోగ సెలవు కోసం అభ్యర్థన\n",
       "ప్రియమైన మేనేజర్,\n",
       "నేను ఆరోగ్యంగా లేను మరియు [విడుదల తేదీలు] కోసం రోగ సెలవు కోరుతున్నాను. నేను తిరిగి వచ్చిన తర్వాత ఎలాంటి పెండింగ్ పనులను పూర్తి చేస్తాను మరియు మార్పులు ఉంటే మీకు సమాచారం అందిస్తాను.\n",
       "మీకు మరింత సమాచారం అవసరమైతే దయచేసి నాకు తెలియజేయండి.\n",
       "\n",
       "**Gujarati:**\n",
       "વિષય: [છુટ્ટા તારીખો] પર બીમારીની રજા માટે વિનંતી\n",
       "પ્રિય મેનેજર,\n",
       "હું અસ્વસ્થ અનુભવી રહ્યો છું અને [છુટ્ટા તારીખો] માટે બીમારીની રજા માંગું છું. હું પાછા ફર્યા પછી કોઈપણ બાકી કામ પૂર્ણ કરવા ખાતરી આપીશ અને જો કોઈ ફેરફાર થાય તો તમને અપડેટ રાખીશ.\n",
       "કૃપા કરીને મને જણાવો કે શું તમને વધુ માહિતીની જરૂર છે.\n",
       "\n",
       "**Marathi:**\n",
       "विषय: [अवकाश तारीख] वर आजारी सुट्टीसाठी विनंती\n",
       "प्रिय व्यवस्थापक,\n",
       "मी अस्वस्थ आहे आणि [अवकाश तारीख] साठी आजारी सुट्टीची विनंती करतो. मी परत आल्यानंतर कोणतीही प्रलंबित कामे पूर्ण करण्याची खात्री करतो आणि कोणतेही बदल झाल्यास तुम्हाला अपडेट ठेवतो.\n",
       "कृपया तुम्हाला आणखी माहिती हवी असल्यास मला कळवा.\n",
       "\n",
       "**Bengali:**\n",
       "বিষয়: [ছুটির তারিখ] এ অসুস্থ ছুটির জন্য আবেদন\n",
       "প্রিয় ম্যানেজার,\n",
       "আমি অসুস্থ অনুভব করছি এবং [ছুটির তারিখ] এ অসুস্থ ছুটির জন্য আবেদন করতে চাই। আমি ফিরে আসার পর যে কোনও বাকি কাজ সম্পন্ন করার নিশ্চয়তা দেব এবং যদি কোনও পরিবর্তন হয় তবে আপনাকে আপডেট রাখব।\n",
       "আপনার যদি আরও তথ্যের প্রয়োজন হয় তবে দয়া করে আমাকে জানান।\n",
       "\n",
       "**Tulu:**\n",
       "ವಿಷಯ: [ಊರ ದಿನಾಂಕಗಳು] ರೋಗಾವಸ್ಥೆ ರಜೆಗೆ ವಿನಂತಿ\n",
       "ಪ್ರಿಯ ಮ್ಯಾನೇಜರ್,\n",
       "ನಾನು ಆರೋಗ್ಯವಾಗಿಲ್ಲ ಮತ್ತು [ಊರ ದಿನಾಂಕಗಳು] ರೋಗಾವಸ್ಥೆ ರಜೆಗೆ ವಿನಂತಿ ಮಾಡುತ್ತೇನೆ. ನಾನು ಹಿಂದಿರುಗಿದ ನಂತರ ಯಾವುದೇ ಬಾಕಿ ಕೆಲಸಗಳನ್ನು ಪೂರ್ಣಗೊಳಿಸಲು ಖಚಿತಪಡಿಸುತ್ತೇನೆ ಮತ್ತು ಯಾವುದೇ ಬದಲಾವಣೆಗಳಿದ್ದರೆ ನಿಮಗೆ ಮಾಹಿತಿ ನೀಡುತ್ತೇನೆ.\n",
       "ನಿಮಗೆ ಇನ್ನಷ್ಟು ಮಾಹಿತಿಯ ಅಗತ್ಯವಿದ್ದರೆ ದಯವಿಟ್ಟು ನನಗೆ ತಿಳಿಸಿ.\n",
       "\n",
       "**Odia:**\n",
       "ବିଷୟ: [ଛୁଟି ତାରିଖ] ରେ ରୋଗ ଛୁଟି ପାଇଁ ଅନୁରୋଧ\n",
       "ପ୍ରିୟ ମ୍ୟାନେଜର,\n",
       "ମୁଁ ଅସୁସ୍ଥ ଅନୁଭବ କରୁଛି ଏବଂ [ଛୁଟି ତାରିଖ] ରେ ରୋଗ ଛୁଟି ପାଇଁ ଅନୁରୋଧ କରୁଛି। ମୁଁ ଫେରିବା ପରେ କୌଣସି ବକି ତାଲିକା କାମ ସମ୍ପୂର୍ଣ୍ଣ କରିବାକୁ ନିଶ୍ଚିତ କରିବି ଏବଂ ଯଦି କୌଣସି ପରିବର୍ତ୍ତନ ହୁଏ ତେବେ ଆପଣଙ୍କୁ ଅପଡେଟ୍ ରଖିବି।\n",
       "ଦୟାକରି ଆପଣଙ୍କୁ ଅଧିକ ସୂଚନା ଆବଶ୍ୟକ ହେଲେ ମୋତେ ଜଣାଇବେ।\n",
       "\n",
       "**Maithili:**\n",
       "विषय: [छुट्टी के तिथि] पर बीमार छुट्टी के लिए अनुरोध\n",
       "प्रिय प्रबंधक,\n",
       "हम अस्वस्थ महसूस कर रहल छी और [छुट्टी के तिथि] पर बीमार छुट्टी के लिए अनुरोध कर रहल छी। हम लौटने के बाद कोई भी लंबित कार्य पूरा करब और यदि कोई परिवर्तन होए त हम अपने के अपडेट रखब।\n",
       "कृपया बताउ कि यदि अपने के और जानकारी के आवश्यकता अछि।\n",
       "\n",
       "**Malayalam:**\n",
       "വിഷയം: [അവധിയുടെ തീയതികൾ] നുള്ള രോഗ അവധിക്ക് അപേക്ഷ\n",
       "പ്രിയ മാനേജർ,\n",
       "ഞാൻ അസുഖം അനുഭവിക്കുന്നു, [അവധിയുടെ തീയതികൾ] നുള്ള രോഗ അവധിക്ക് അപേക്ഷിക്കാനാണ് ആഗ്രഹിക്കുന്നത്. ഞാൻ തിരികെ വന്ന ശേഷം ബാക്കി ഉള്ള എല്ലാ ജോലികളും പൂർത്തിയാക്കാൻ ഉറപ്പുനൽകുന്നു, കൂടാതെ മാറ്റങ്ങൾ ഉണ്ടെങ്കിൽ നിങ്ങളെ അപ്ഡേറ്റ് ചെയ്യാൻ ഞാൻ ശ്രമിക്കും.\n",
       "കൂടുതൽ വിവരങ്ങൾ ആവശ്യമുണ്ടെങ്കിൽ ദയവായി എന്നെ അറിയിക്കുക.\n",
       "\n",
       "**Kannada:**\n",
       "ವಿಷಯ: [ಅವಕಾಶ ದಿನಾಂಕಗಳು] ರೋಗ ರಜೆಗೆ ವಿನಂತಿ\n",
       "ಪ್ರಿಯ ಮ್ಯಾನೇಜರ್,\n",
       "ನಾನು ಆರೋಗ್ಯವಾಗಿಲ್ಲ ಮತ್ತು [ಅವಕಾಶ ದಿನಾಂಕಗಳು] ರೋಗ ರಜೆಗೆ ವಿನಂತಿ ಮಾಡುತ್ತೇನೆ. ನಾನು ಹಿಂದಿರುಗಿದ ನಂತರ ಯಾವುದೇ ಬಾಕಿ ಕೆಲಸಗಳನ್ನು ಪೂರ್ಣಗೊಳಿಸಲು ಖಚಿತಪಡಿಸುತ್ತೇನೆ ಮತ್ತು ಯಾವುದೇ ಬದಲಾವಣೆಗಳಿದ್ದರೆ ನಿಮಗೆ ಮಾಹಿತಿ ನೀಡುತ್ತೇನೆ.\n",
       "ನಿಮಗೆ ಇನ್ನಷ್ಟು ಮಾಹಿತಿಯ ಅಗತ್ಯವಿದ್ದರೆ ದಯವಿಟ್ಟು ನನಗೆ ತಿಳಿಸಿ.\n",
       "\n",
       "**Punjabi:**\n",
       "ਵਿਸ਼ਾ: [ਛੁੱਟੀ ਦੀਆਂ ਤਾਰੀਖਾਂ] 'ਤੇ ਬਿਮਾਰੀ ਦੀ ਛੁੱਟੀ ਲਈ ਬੇਨਤੀ\n",
       "ਪਿਆਰੇ ਮੈਨੇਜਰ,\n",
       "ਮੈਂ ਅਸੁਥ ਹੋ ਰਿਹਾ ਹਾਂ ਅਤੇ [ਛੁੱਟੀ ਦੀਆਂ ਤਾਰੀਖਾਂ] ਲਈ ਬਿਮਾਰੀ ਦੀ ਛੁੱਟੀ ਦੀ ਬੇਨਤੀ ਕਰਨਾ ਚਾਹੁੰਦਾ ਹਾਂ। ਮੈਂ ਵਾਪਸ ਆਉਣ 'ਤੇ ਕਿਸੇ ਵੀ ਬਾਕੀ ਕੰਮ ਨੂੰ ਪੂਰਾ ਕਰਨ ਦੀ ਯਕੀਨੀ ਬਣਾਵਾਂਗਾ ਅਤੇ ਜੇ ਕੋਈ ਬਦਲਾਅ ਹੋਵੇ ਤਾਂ ਤੁਹਾਨੂੰ ਅਪਡੇਟ ਰੱਖਾਂਗਾ।\n",
       "ਕਿਰਪਾ ਕਰਕੇ ਮੈਨੂੰ ਦੱਸੋ ਕਿ ਕੀ ਤੁਹਾਨੂੰ ਹੋਰ ਜਾਣਕਾਰੀ ਦੀ ਲੋੜ ਹੈ।\n",
       "\n",
       "**Nepali:**\n",
       "विषय: [छुट्टीको मिति] मा बिरामी बिदाको लागि अनुरोध\n",
       "प्रिय प्रबन्धक,\n",
       "म अस्वस्थ महसुस गर्दैछु र [छुट्टीको मिति] मा बिरामी बिदाको लागि अनुरोध गर्न चाहन्छु। म फर्केपछि कुनै पनि बाँकी काम पूरा गर्ने सुनिश्चित गर्नेछु र यदि कुनै परिवर्तन भएमा तपाईंलाई अपडेट राख्नेछु।\n",
       "कृपया मलाई बताउनुहोस् कि यदि तपाईंलाई थप जानकारीको आवश्यकता छ भने। \n",
       "\n",
       "Feel free to ask if you need any further assistance!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"You are an expert translator. Translate the given text from English to German, Spanish, Hindi, Tamil, Telgu, \n",
    "Gujarati, Marathi, Bengali, tulu, oriya, maithili, malayalam,kannada,punjabi, and nepali.\n",
    "\n",
    "Text:\"Subject: Request for Sick Leave on [Leave Dates]\n",
    "Dear Manager,\n",
    "I am feeling unwell and would like to request sick leave for [Leave Dates]. I will ensure to complete any pending tasks once I return and keep you updated if there are any changes.\n",
    "Please let me know if you need any further information.\"\n",
    "\n",
    "Transaltion:\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11b1ad22-d01b-4ebd-a67e-fd78c4738e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the translations for \"Hi, how are you\" in the requested languages:\n",
       "\n",
       "- **German**: \"Hallo, wie geht es dir?\"\n",
       "- **Spanish**: \"Hola, ¿cómo estás?\"\n",
       "- **Hindi**: \"नमस्ते, आप कैसे हैं?\"\n",
       "- **Tamil**: \"வணக்கம், நீங்கள் எப்படி இருக்கிறீர்கள்?\"\n",
       "- **Telugu**: \"హాయ్, మీరు ఎలా ఉన్నారు?\"\n",
       "- **Gujarati**: \"હાય, તમે કેમ છો?\"\n",
       "- **Marathi**: \"नमस्कार, तुम्ही कसे आहात?\"\n",
       "- **Bengali**: \"হ্যালো, তুমি কেমন আছো?\"\n",
       "- **Tulu**: \"ನಮಸ್ಕಾರ, ನಿನಗೆ ಹೇಗಿದೆ?\"\n",
       "- **Oriya**: \"ନମସ୍କାର, ତୁମେ କେମିତି ଅଛ?\"\n",
       "- **Maithili**: \"नमस्कार, अहाँ केहन छी?\"\n",
       "- **Malayalam**: \"ഹായ്, നീ എങ്ങനെയുണ്ട്?\"\n",
       "- **Kannada**: \"ಹಾಯ್, ನೀವು ಹೇಗಿದ್ದೀರಿ?\"\n",
       "- **Punjabi**: \"ਸਤ ਸ੍ਰੀ ਅਕਾਲ, ਤੁਸੀਂ ਕਿਵੇਂ ਹੋ?\"\n",
       "- **Nepali**: \"नमस्ते, तपाईँलाई कस्तो छ?\"\n",
       "\n",
       "If you need any further assistance, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"You are an expert translator. Translate the given text from English to German, Spanish, Hindi, Tamil, Telgu, \n",
    "Gujarati, Marathi, Bengali, tulu, oriya, maithili, malayalam,kannada,punjabi, and nepali.\n",
    "\n",
    "Text:\"Hi, how are you\"\n",
    "\n",
    "Transaltion:\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c93e8-0a7e-4fe0-8ce7-abbfd311a9e6",
   "metadata": {},
   "source": [
    "# Task 7 - Document Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b9c79a8b-3a9d-4345-82be-b8ee71d72f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "Coronaviruses are a large family of viruses which may cause illness in animals or humans.\n",
    "In humans, several coronaviruses are known to cause respiratory infections ranging from the\n",
    "common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS).\n",
    "The most recently discovered coronavirus causes coronavirus disease COVID-19.\n",
    "COVID-19 is the infectious disease caused by the most recently discovered coronavirus.\n",
    "This new virus and disease were unknown before the outbreak began in Wuhan, China, in December 2019.\n",
    "COVID-19 is now a pandemic affecting many countries globally.\n",
    "The most common symptoms of COVID-19 are fever, dry cough, and tiredness.\n",
    "Other symptoms that are less common and may affect some patients include aches\n",
    "and pains, nasal congestion, headache, conjunctivitis, sore throat, diarrhea,\n",
    "loss of taste or smell or a rash on skin or discoloration of fingers or toes.\n",
    "These symptoms are usually mild and begin gradually.\n",
    "Some people become infected but only have very mild symptoms.\n",
    "Most people (about 80%) recover from the disease without needing hospital treatment.\n",
    "Around 1 out of every 5 people who gets COVID-19 becomes seriously ill and develops difficulty breathing.\n",
    "Older people, and those with underlying medical problems like high blood pressure, heart and lung problems,\n",
    "diabetes, or cancer, are at higher risk of developing serious illness.\n",
    "However, anyone can catch COVID-19 and become seriously ill.\n",
    "People of all ages who experience fever and/or  cough associated with difficulty breathing/shortness of breath,\n",
    "chest pain/pressure, or loss of speech or movement should seek medical attention immediately.\n",
    "If possible, it is recommended to call the health care provider or facility first,\n",
    "so the patient can be directed to the right clinic.\n",
    "People can catch COVID-19 from others who have the virus.\n",
    "The disease spreads primarily from person to person through small droplets from the nose or mouth,\n",
    "which are expelled when a person with COVID-19 coughs, sneezes, or speaks.\n",
    "These droplets are relatively heavy, do not travel far and quickly sink to the ground.\n",
    "People can catch COVID-19 if they breathe in these droplets from a person infected with the virus.\n",
    "This is why it is important to stay at least 1 meter) away from others.\n",
    "These droplets can land on objects and surfaces around the person such as tables, doorknobs and handrails.\n",
    "People can become infected by touching these objects or surfaces, then touching their eyes, nose or mouth.\n",
    "This is why it is important to wash your hands regularly with soap and water or clean with alcohol-based hand rub.\n",
    "Practicing hand and respiratory hygiene is important at ALL times and is the best way to protect others and yourself.\n",
    "When possible maintain at least a 1 meter distance between yourself and others.\n",
    "This is especially important if you are standing by someone who is coughing or sneezing.\n",
    "Since some infected persons may not yet be exhibiting symptoms or their symptoms may be mild,\n",
    "maintaining a physical distance with everyone is a good idea if you are in an area where COVID-19 is circulating.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d7a91e4e-7bdc-4577-a7fd-bfb1a0f4f86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "SUMMARY: Coronaviruses can cause respiratory infections in humans, with COVID-19 being the most recent and severe outbreak, first identified in Wuhan, China, in December 2019. Common symptoms include fever, cough, and tiredness, while serious cases can lead to difficulty breathing, especially in older adults and those with underlying health issues. The virus spreads primarily through respiratory droplets, making physical distancing and hand hygiene crucial for prevention. Most people recover without hospitalization, but immediate medical attention is advised for severe symptoms."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are an expert in generating accurate document summaries.\n",
    "Generate a summary of the given document.\n",
    "\n",
    "Document:\n",
    "{doc}\n",
    "\n",
    "constraints: Please start the summary with the delimiter \"SUMMARY :\" and limit the summary to 5 lines only\n",
    "\n",
    "SUMMARY:\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "783b32ad-ac9b-485f-9ecd-0ddcecf6f55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBy calling for an all-party meeting on March 5 to discuss the delimitation exercise, Tamil Nadu Chief Minister M.K. Stalin has sought to stir up a national debate. Delimitation, as an exercise, has not seen any increase in the legislative seats since 1973, having been frozen as per the 1971 Census for parity in population growth across States. This was done to prevent States with a higher population growth from getting “rewarded” with a higher number of representatives at the cost of other States with better health indices and lower growth. The 84th constitutional Amendment had stipulated that the delimitation exercise would be based on the first Census after 2026. Is the Union government inexplicably delaying the Census exercise to allow for the delimitation exercise to be held earlier? In the normal scheme of things, the exercise would have been done after the 2031 Census, but it is now possible after 2026 once the Census (due in 2021), is conducted.\\nThe concern of Tamil Nadu that the exercise could hurt its representation in Parliament is legitimate if the Centre intends the process to be only proportionally representative of each State’s population. This is illustrated in the population growth rates (1971-2024) in Tamil Nadu and undivided Bihar. The electorate, for which recent data is available, grew by 171% in the former as against 233% in the latter, while they had a comparable number of Lok Sabha MPs (39 versus 54, including Jharkhand). If delimitation was held and constituencies redrawn to match population growth, and even if the overall Lok Sabha tally was increased, the final number for Tamil Nadu would clearly be much lower than Bihar’s. Other States with reduced fertility rates, such as Kerala and Karnataka, will also be affected. Home Minister Amit Shah has said that there will be no “reduction on a pro-rata basis” for Southern States and that they would get their “rightful share” but there has been little clarity on whether this would mean that their proportion of representatives will be retained after delimitation. The significant increase in population since 1973 should lead to an increased number of representatives, and, therefore, a higher number of seats, especially in north India’s highly populated States. Yet, the equally important principle of federalism should suggest the need for the proportions of representation to be maintained to keep the balance of power intact across States. More importantly, the government must expedite the Census just to allay concerns that it has been delayed to facilitate an earlier and controversial delimitation. A nation striving to reach the higher pedestals of world power cannot afford to delay the basic exercise of counting the number of its own people.\\n\\n\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editorial = f\"\"\"\n",
    "By calling for an all-party meeting on March 5 to discuss the delimitation exercise, Tamil Nadu Chief Minister M.K. Stalin has sought to stir up a national debate. Delimitation, as an exercise, has not seen any increase in the legislative seats since 1973, having been frozen as per the 1971 Census for parity in population growth across States. This was done to prevent States with a higher population growth from getting “rewarded” with a higher number of representatives at the cost of other States with better health indices and lower growth. The 84th constitutional Amendment had stipulated that the delimitation exercise would be based on the first Census after 2026. Is the Union government inexplicably delaying the Census exercise to allow for the delimitation exercise to be held earlier? In the normal scheme of things, the exercise would have been done after the 2031 Census, but it is now possible after 2026 once the Census (due in 2021), is conducted.\n",
    "The concern of Tamil Nadu that the exercise could hurt its representation in Parliament is legitimate if the Centre intends the process to be only proportionally representative of each State’s population. This is illustrated in the population growth rates (1971-2024) in Tamil Nadu and undivided Bihar. The electorate, for which recent data is available, grew by 171% in the former as against 233% in the latter, while they had a comparable number of Lok Sabha MPs (39 versus 54, including Jharkhand). If delimitation was held and constituencies redrawn to match population growth, and even if the overall Lok Sabha tally was increased, the final number for Tamil Nadu would clearly be much lower than Bihar’s. Other States with reduced fertility rates, such as Kerala and Karnataka, will also be affected. Home Minister Amit Shah has said that there will be no “reduction on a pro-rata basis” for Southern States and that they would get their “rightful share” but there has been little clarity on whether this would mean that their proportion of representatives will be retained after delimitation. The significant increase in population since 1973 should lead to an increased number of representatives, and, therefore, a higher number of seats, especially in north India’s highly populated States. Yet, the equally important principle of federalism should suggest the need for the proportions of representation to be maintained to keep the balance of power intact across States. More importantly, the government must expedite the Census just to allay concerns that it has been delayed to facilitate an earlier and controversial delimitation. A nation striving to reach the higher pedestals of world power cannot afford to delay the basic exercise of counting the number of its own people.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "editorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7ab62ed-a5ae-43f2-96d4-2842d81d0a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "SUMMARY: Tamil Nadu Chief Minister M.K. Stalin has called for an all-party meeting on March 5 to discuss the implications of the delimitation exercise, which has not seen an increase in legislative seats since 1973. Concerns arise that the Union government may delay the Census to facilitate earlier delimitation, potentially reducing Tamil Nadu's parliamentary representation. Home Minister Amit Shah has assured that Southern States will retain their rightful share, but clarity is lacking. The document emphasizes the need for an expedited Census to address these concerns and maintain federal balance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are an expert in generating accurate document summaries.\n",
    "Generate a summary of the given document.\n",
    "\n",
    "Document:\n",
    "{editorial}\n",
    "\n",
    "constraints: Please start the summary with the delimiter \"SUMMARY :\" and limit the summary to 5 lines only\n",
    "\n",
    "SUMMARY:\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98b615-44a2-46ff-8899-f35968269bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e5e49-b593-4190-9dcf-35c13c0dfd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b672142b-a277-4064-a501-78122bbd5378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda775f-0b97-4ed5-a8f5-7c2b1f4c7b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af3530-fe5d-444e-ac8f-4bc6379961f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
