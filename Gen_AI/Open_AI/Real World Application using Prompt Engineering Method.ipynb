{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c91c2d5b-205c-4bf1-8d7f-7b5b877e1b58",
   "metadata": {},
   "source": [
    "# Task 1 - Zero Shot Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee6016-6020-4d53-b859-369781fb51d2",
   "metadata": {},
   "source": [
    "### Load OpenAI API Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9726e81b-acaf-45bb-984d-aa00a0ec7dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your openai API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "openai_key = getpass(\"Enter your openai API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6525236-c8c8-40b7-8bf2-1609579d4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from IPython.display import HTML\n",
    "openai.api_key= openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f377fb0-49c5-4320-ac8c-3fe5fa64cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
    "    messages = [{\"role\":\"user\", \"content\":prompt}]\n",
    "    response = openai.chat.completions.create(model = model, messages=messages, temperature=0)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10bd1c8-afac-4942-906c-92cd882dd4ec",
   "metadata": {},
   "source": [
    "### Let's try out the ChatGPT API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0936bb5-9c60-41a4-a973-678af2345fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edd00828-afee-4214-9451-3c1d56094b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Understanding Decision Trees: A Comprehensive Guide\n",
       "\n",
       "In the realm of machine learning and data science, decision trees stand out as one of the most intuitive and widely used algorithms. Their simplicity, interpretability, and effectiveness make them a popular choice for both beginners and seasoned professionals. In this blog, we will explore what decision trees are, how they work, their advantages and disadvantages, and some practical applications.\n",
       "\n",
       "## What is a Decision Tree?\n",
       "\n",
       "A decision tree is a flowchart-like structure used for classification and regression tasks. It consists of nodes that represent features (or attributes) of the data, branches that represent decision rules, and leaves that represent outcomes (or target values). The tree is built by splitting the data into subsets based on the value of the features, ultimately leading to a decision or prediction.\n",
       "\n",
       "### Structure of a Decision Tree\n",
       "\n",
       "1. **Root Node**: The top node of the tree, representing the entire dataset.\n",
       "2. **Decision Nodes**: Nodes that split the data based on certain conditions.\n",
       "3. **Leaf Nodes**: Terminal nodes that provide the final output or prediction.\n",
       "4. **Branches**: The connections between nodes that represent the flow of decisions.\n",
       "\n",
       "## How Decision Trees Work\n",
       "\n",
       "The process of building a decision tree involves several steps:\n",
       "\n",
       "1. **Selecting the Best Feature**: The algorithm evaluates all features and selects the one that best separates the data into distinct classes. Common criteria for this selection include:\n",
       "   - **Gini Impurity**: Measures the impurity of a dataset. A lower Gini score indicates a better split.\n",
       "   - **Entropy**: Measures the amount of disorder or uncertainty in the dataset. The goal is to minimize entropy after the split.\n",
       "   - **Mean Squared Error (MSE)**: Used for regression tasks to minimize the variance in the target variable.\n",
       "\n",
       "2. **Splitting the Data**: Once the best feature is selected, the data is split into subsets based on the feature's values.\n",
       "\n",
       "3. **Recursion**: The process is repeated for each subset, creating new decision nodes until a stopping criterion is met (e.g., maximum depth, minimum samples per leaf, or no further improvement).\n",
       "\n",
       "4. **Pruning**: To avoid overfitting, the tree may be pruned by removing nodes that provide little predictive power.\n",
       "\n",
       "## Advantages of Decision Trees\n",
       "\n",
       "- **Interpretability**: Decision trees are easy to understand and visualize, making them accessible for non-technical stakeholders.\n",
       "- **No Need for Feature Scaling**: Unlike algorithms such as SVM or K-means, decision trees do not require normalization or standardization of features.\n",
       "- **Handles Both Numerical and Categorical Data**: Decision trees can work with various data types without the need for extensive preprocessing.\n",
       "- **Robust to Outliers**: Decision trees are less sensitive to outliers compared to other algorithms.\n",
       "\n",
       "## Disadvantages of Decision Trees\n",
       "\n",
       "- **Overfitting**: Decision trees can easily become too complex, capturing noise in the data rather than the underlying pattern.\n",
       "- **Instability**: Small changes in the data can lead to different tree structures, making them less robust.\n",
       "- **Bias towards Dominant Classes**: In imbalanced datasets, decision trees may favor the majority class.\n",
       "\n",
       "## Practical Applications of Decision Trees\n",
       "\n",
       "Decision trees are versatile and can be applied in various domains, including:\n",
       "\n",
       "- **Healthcare**: Predicting patient outcomes based on medical history and symptoms.\n",
       "- **Finance**: Assessing credit risk and determining loan approvals.\n",
       "- **Marketing**: Segmenting customers based on purchasing behavior and preferences.\n",
       "- **Manufacturing**: Predicting equipment failures and optimizing maintenance schedules.\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Decision trees are a powerful tool in the data scientist's toolkit, offering a blend of simplicity and effectiveness. While they have their limitations, understanding how to leverage decision trees can lead to valuable insights and predictions across various fields. As you delve deeper into machine learning, consider incorporating decision trees into your projects, and explore their potential to enhance your data-driven decision-making processes. \n",
       "\n",
       "Whether you're a beginner or an experienced practitioner, mastering decision trees can significantly enhance your analytical capabilities and help you tackle complex problems with confidence. Happy learning!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = get_completion(prompt=\"Write a blog about DecisionTree\", model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c02dc485-eac0-4b07-a82c-e74aeb2162e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Understanding Decision Trees: A Comprehensive Guide\n",
      "\n",
      "In the realm of machine learning and data science, decision trees stand out as one of the most intuitive and widely used algorithms. Their simplicity, interpretability, and effectiveness make them a popular choice for both beginners and seasoned professionals. In this blog, we will explore what decision trees are, how they work, their advantages and disadvantages, and some practical applications.\n",
      "\n",
      "## What is a Decision Tree?\n",
      "\n",
      "A decision tree is a flowchart-like structure used for classification and regression tasks. It consists of nodes that represent features (or attributes) of the data, branches that represent decision rules, and leaves that represent outcomes (or target values). The tree is built by splitting the data into subsets based on the value of the features, ultimately leading to a decision or prediction.\n",
      "\n",
      "### Structure of a Decision Tree\n",
      "\n",
      "1. **Root Node**: The top node of the tree, representing the entire dataset.\n",
      "2. **Decision Nodes**: Nodes that split the data based on certain conditions.\n",
      "3. **Leaf Nodes**: Terminal nodes that provide the final output or prediction.\n",
      "4. **Branches**: The connections between nodes that represent the flow of decisions.\n",
      "\n",
      "## How Decision Trees Work\n",
      "\n",
      "The process of building a decision tree involves several steps:\n",
      "\n",
      "1. **Selecting the Best Feature**: The algorithm evaluates all features and selects the one that best separates the data into distinct classes. Common criteria for this selection include:\n",
      "   - **Gini Impurity**: Measures the impurity of a dataset. A lower Gini score indicates a better split.\n",
      "   - **Entropy**: Measures the amount of disorder or uncertainty in the dataset. The goal is to minimize entropy after the split.\n",
      "   - **Mean Squared Error (MSE)**: Used for regression tasks to minimize the variance in the target variable.\n",
      "\n",
      "2. **Splitting the Data**: Once the best feature is selected, the data is split into subsets based on the feature's values.\n",
      "\n",
      "3. **Recursion**: The process is repeated for each subset, creating new decision nodes until a stopping criterion is met (e.g., maximum depth, minimum samples per leaf, or no further improvement).\n",
      "\n",
      "4. **Pruning**: To avoid overfitting, the tree may be pruned by removing nodes that provide little predictive power.\n",
      "\n",
      "## Advantages of Decision Trees\n",
      "\n",
      "- **Interpretability**: Decision trees are easy to understand and visualize, making them accessible for non-technical stakeholders.\n",
      "- **No Need for Feature Scaling**: Unlike algorithms such as SVM or K-means, decision trees do not require normalization or standardization of features.\n",
      "- **Handles Both Numerical and Categorical Data**: Decision trees can work with various data types without the need for extensive preprocessing.\n",
      "- **Robust to Outliers**: Decision trees are less sensitive to outliers compared to other algorithms.\n",
      "\n",
      "## Disadvantages of Decision Trees\n",
      "\n",
      "- **Overfitting**: Decision trees can easily become too complex, capturing noise in the data rather than the underlying pattern.\n",
      "- **Instability**: Small changes in the data can lead to different tree structures, making them less robust.\n",
      "- **Bias towards Dominant Classes**: In imbalanced datasets, decision trees may favor the majority class.\n",
      "\n",
      "## Practical Applications of Decision Trees\n",
      "\n",
      "Decision trees are versatile and can be applied in various domains, including:\n",
      "\n",
      "- **Healthcare**: Predicting patient outcomes based on medical history and symptoms.\n",
      "- **Finance**: Assessing credit risk and determining loan approvals.\n",
      "- **Marketing**: Segmenting customers based on purchasing behavior and preferences.\n",
      "- **Manufacturing**: Predicting equipment failures and optimizing maintenance schedules.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Decision trees are a powerful tool in the data scientist's toolkit, offering a blend of simplicity and effectiveness. While they have their limitations, understanding how to leverage decision trees can lead to valuable insights and predictions across various fields. As you delve deeper into machine learning, consider incorporating decision trees into your projects, and explore their potential to enhance your data-driven decision-making processes. \n",
      "\n",
      "Whether you're a beginner or an experienced practitioner, mastering decision trees can significantly enhance your analytical capabilities and help you tackle complex problems with confidence. Happy learning!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20776319-e0c8-47af-b7ca-9c3439dd65f3",
   "metadata": {},
   "source": [
    "# Task 1 - Zero-Shot Classification ( without providing any output examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5b2382b-13a4-404d-8269-85c772431794",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    f\"\"\"\n",
    "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
    "    The sound quality is impressively clear with just the right amount of bass.\n",
    "    It's also waterproof, which tested true during a recent splashing incident.\n",
    "    Though it's compact, the volume can really fill the space.\n",
    "    The price was a bargain for such high-quality sound.\n",
    "    Shipping was also on point, arriving two days early in secure packaging.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    Needed a new kitchen blender, but this model has been a nightmare.\n",
    "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
    "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
    "    I thought the brand meant quality, but this product has proven me wrong.\n",
    "    Plus, it arrived three days late. Definitely not worth the expense.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf068770-41b5-4791-9fda-d6db4cdfedd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = []\n",
    "\n",
    "for review in reviews:\n",
    "    prompt = f\"\"\"\n",
    "    Act as a product review analyst. Given the following review, display the overall sentiment for the review as only one of the following:\n",
    "    Positive, Negative OR Neutral\n",
    "\n",
    "    '''{review}'''\n",
    "    \"\"\"\n",
    "    responses = get_completion(prompt=prompt, model=\"gpt-4o-mini\")\n",
    "    response.append(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "554b88f6-02a7-477d-a8a0-38be8c38d4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:  \n",
      "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
      "    The sound quality is impressively clear with just the right amount of bass.\n",
      "    It's also waterproof, which tested true during a recent splashing incident.\n",
      "    Though it's compact, the volume can really fill the space.\n",
      "    The price was a bargain for such high-quality sound.\n",
      "    Shipping was also on point, arriving two days early in secure packaging.\n",
      "    \n",
      "Sentiment : Positive\n",
      "***************************\n",
      "\n",
      "\n",
      "Review:  \n",
      "    Needed a new kitchen blender, but this model has been a nightmare.\n",
      "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
      "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
      "    I thought the brand meant quality, but this product has proven me wrong.\n",
      "    Plus, it arrived three days late. Definitely not worth the expense.\n",
      "    \n",
      "Sentiment : Negative\n",
      "***************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for review, response in zip(reviews, response):\n",
    "    print(\"Review: \", review)\n",
    "    print(\"Sentiment :\", response)\n",
    "    print(\"***************************\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e860e46-440e-43a1-a375-7672e3151ecd",
   "metadata": {},
   "source": [
    "# Task 2 - Few-Shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14e8cc84-b19c-4192-93cd-6886facc6c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = []\n",
    "\n",
    "for review in reviews:\n",
    "    prompt = f\"\"\"\n",
    "              Act as a product review analyst.\n",
    "              Given the following review,\n",
    "              Display only the overall sentiment for the review:\n",
    "\n",
    "              Try to classify it by using the following examples as a reference:\n",
    "\n",
    "              Review: Just received the Laptop I ordered for work, and it's amazing.\n",
    "              Sentiment: 😊\n",
    "\n",
    "              Review: Needed a new mechanical keyboard, but this model has been totally disappointing.\n",
    "              Sentiment: 😡\n",
    "\n",
    "              Review: ```{review}```\n",
    "              \"\"\"\n",
    "    responses = get_completion(prompt=prompt, model=\"gpt-4o-mini\")\n",
    "    response.append(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a079463-d729-4b5f-ab15-c240e69d76ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:  \n",
      "    Just received the Bluetooth speaker I ordered for beach outings, and it's fantastic.\n",
      "    The sound quality is impressively clear with just the right amount of bass.\n",
      "    It's also waterproof, which tested true during a recent splashing incident.\n",
      "    Though it's compact, the volume can really fill the space.\n",
      "    The price was a bargain for such high-quality sound.\n",
      "    Shipping was also on point, arriving two days early in secure packaging.\n",
      "    \n",
      "Sentiment : Sentiment: 😊\n",
      "***************************\n",
      "\n",
      "\n",
      "Review:  \n",
      "    Needed a new kitchen blender, but this model has been a nightmare.\n",
      "    It's supposed to handle various foods, but it struggles with anything tougher than cooked vegetables.\n",
      "    It's also incredibly noisy, and the 'easy-clean' feature is a joke; food gets stuck under the blades constantly.\n",
      "    I thought the brand meant quality, but this product has proven me wrong.\n",
      "    Plus, it arrived three days late. Definitely not worth the expense.\n",
      "    \n",
      "Sentiment : Sentiment: 😡\n",
      "***************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for review, response in zip(reviews, response):\n",
    "    print(\"Review: \", review)\n",
    "    print(\"Sentiment :\", response)\n",
    "    print(\"***************************\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68468f22-a777-44a0-ac3b-f4a97b1614d2",
   "metadata": {},
   "source": [
    "# Task 3 - Coding Tasks - Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a35d5a0b-55fc-453e-92de-c3bf654345d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To create a \"chain of thought\" prompt pattern for deep seeking using the OpenAI Python library, we can structure the code to generate a prompt that encourages the model to think step-by-step through a problem. This approach is particularly useful for complex tasks where reasoning is required.\n",
       "\n",
       "Below is an example of how to implement this in Python using the OpenAI library. Make sure you have the OpenAI library installed (`pip install openai`) and that you have your API key set up.\n",
       "\n",
       "```python\n",
       "import openai\n",
       "\n",
       "# Set your OpenAI API key\n",
       "openai.api_key = 'your-api-key-here'\n",
       "\n",
       "def generate_chain_of_thought_prompt(question):\n",
       "    # Create a prompt that encourages a step-by-step reasoning process\n",
       "    prompt = (\n",
       "        \"Let's think through this step by step. \"\n",
       "        \"I will break down the problem and analyze each part. \"\n",
       "        f\"Here is the question: {question}\\n\\n\"\n",
       "        \"1. First, I need to understand the key components of the question.\\n\"\n",
       "        \"2. Next, I will identify any relevant information or concepts.\\n\"\n",
       "        \"3. Then, I will analyze how these components interact with each other.\\n\"\n",
       "        \"4. Finally, I will draw a conclusion based on my analysis.\\n\\n\"\n",
       "        \"Now, let's start with step 1.\"\n",
       "    )\n",
       "    return prompt\n",
       "\n",
       "def get_response_from_openai(prompt):\n",
       "    response = openai.ChatCompletion.create(\n",
       "        model=\"gpt-3.5-turbo\",  # or any other model you want to use\n",
       "        messages=[\n",
       "            {\"role\": \"user\", \"content\": prompt}\n",
       "        ],\n",
       "        max_tokens=1500,  # Adjust based on your needs\n",
       "        temperature=0.7,  # Adjust for creativity\n",
       "    )\n",
       "    return response['choices'][0]['message']['content']\n",
       "\n",
       "def main():\n",
       "    question = \"What are the implications of quantum computing on cryptography?\"\n",
       "    prompt = generate_chain_of_thought_prompt(question)\n",
       "    response = get_response_from_openai(prompt)\n",
       "    print(\"Response from OpenAI:\\n\", response)\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    main()\n",
       "```\n",
       "\n",
       "### Explanation:\n",
       "1. **API Key**: Replace `'your-api-key-here'` with your actual OpenAI API key.\n",
       "2. **Prompt Generation**: The `generate_chain_of_thought_prompt` function creates a structured prompt that guides the model to think through the question step-by-step.\n",
       "3. **OpenAI API Call**: The `get_response_from_openai` function sends the generated prompt to the OpenAI API and retrieves the response.\n",
       "4. **Main Function**: The `main` function sets a sample question, generates the prompt, and prints the response from the model.\n",
       "\n",
       "### Usage:\n",
       "- You can modify the `question` variable in the `main` function to test different queries.\n",
       "- Adjust the `max_tokens` and `temperature` parameters in the API call to control the length and creativity of the response.\n",
       "\n",
       "This code provides a framework for generating a \"chain of thought\" prompt pattern that can be adapted for various questions and scenarios."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt =f\"\"\"\n",
    "Act as an expert in generating python code.\n",
    "\n",
    "Your task is to generate python code to build a \"chain of thought\" prompt pattern how deep seek r1 using\n",
    "by openai python library\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2a1e27b-8828-4b43-8afa-e905adcd5cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To build a supervised machine learning model using Logistic Regression on the Titanic dataset, you can use the `pandas`, `scikit-learn`, and `numpy` libraries in Python. Below is a step-by-step guide along with the code to achieve this.\n",
       "\n",
       "### Step 1: Install Required Libraries\n",
       "Make sure you have the required libraries installed. You can install them using pip if you haven't done so already:\n",
       "\n",
       "```bash\n",
       "pip install pandas scikit-learn numpy\n",
       "```\n",
       "\n",
       "### Step 2: Load the Titanic Dataset\n",
       "You can download the Titanic dataset from Kaggle or use a CSV file if you have it locally. For this example, let's assume you have a CSV file named `titanic.csv`.\n",
       "\n",
       "### Step 3: Preprocess the Data\n",
       "You need to preprocess the data by handling missing values, encoding categorical variables, and selecting relevant features.\n",
       "\n",
       "### Step 4: Build and Train the Logistic Regression Model\n",
       "Finally, you will build and train the Logistic Regression model.\n",
       "\n",
       "Here is the complete code:\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "from sklearn.linear_model import LogisticRegression\n",
       "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
       "\n",
       "# Step 1: Load the dataset\n",
       "data = pd.read_csv('titanic.csv')\n",
       "\n",
       "# Step 2: Preprocess the data\n",
       "# Drop columns that are not useful for prediction\n",
       "data = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
       "\n",
       "# Fill missing values\n",
       "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
       "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
       "\n",
       "# Convert categorical variables to numerical\n",
       "data = pd.get_dummies(data, columns=['Sex', 'Embarked'], drop_first=True)\n",
       "\n",
       "# Step 3: Define features and target variable\n",
       "X = data.drop('Survived', axis=1)\n",
       "y = data['Survived']\n",
       "\n",
       "# Step 4: Split the dataset into training and testing sets\n",
       "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
       "\n",
       "# Step 5: Feature scaling\n",
       "scaler = StandardScaler()\n",
       "X_train = scaler.fit_transform(X_train)\n",
       "X_test = scaler.transform(X_test)\n",
       "\n",
       "# Step 6: Create and train the Logistic Regression model\n",
       "model = LogisticRegression()\n",
       "model.fit(X_train, y_train)\n",
       "\n",
       "# Step 7: Make predictions\n",
       "y_pred = model.predict(X_test)\n",
       "\n",
       "# Step 8: Evaluate the model\n",
       "accuracy = accuracy_score(y_test, y_pred)\n",
       "conf_matrix = confusion_matrix(y_test, y_pred)\n",
       "class_report = classification_report(y_test, y_pred)\n",
       "\n",
       "print(f'Accuracy: {accuracy:.2f}')\n",
       "print('Confusion Matrix:')\n",
       "print(conf_matrix)\n",
       "print('Classification Report:')\n",
       "print(class_report)\n",
       "```\n",
       "\n",
       "### Explanation of the Code:\n",
       "1. **Loading the Dataset**: The Titanic dataset is loaded into a pandas DataFrame.\n",
       "2. **Preprocessing**:\n",
       "   - Unnecessary columns are dropped.\n",
       "   - Missing values in the 'Age' and 'Embarked' columns are filled.\n",
       "   - Categorical variables ('Sex' and 'Embarked') are converted to numerical using one-hot encoding.\n",
       "3. **Feature and Target Definition**: Features (X) and target variable (y) are defined.\n",
       "4. **Train-Test Split**: The dataset is split into training and testing sets.\n",
       "5. **Feature Scaling**: StandardScaler is used to standardize the features.\n",
       "6. **Model Creation and Training**: A Logistic Regression model is created and trained on the training data.\n",
       "7. **Predictions**: Predictions are made on the test set.\n",
       "8. **Evaluation**: The model's accuracy, confusion matrix, and classification report are printed.\n",
       "\n",
       "Make sure to adjust the path to the Titanic dataset CSV file as needed. This code provides a basic implementation of Logistic Regression for the Titanic dataset. You can further enhance it by performing more advanced feature engineering, hyperparameter tuning, and model evaluation techniques."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt =f\"\"\"\n",
    "Act as an expert in generating python code.\n",
    "\n",
    "Your task is to generate python code to build a \"supervised maching learning by using Logistic Regression\" for\n",
    "Titanic Dataset by openai python library\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01e09b75-5c50-4032-98e2-93e70348100d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To build a supervised machine learning model using a Deep Neural Network (MLP) for the Titanic dataset, we will follow the steps you outlined: preprocessing the data, treating missing values, encoding categorical variables, scaling features, handling outliers, and addressing class imbalance. Below is a complete Python code that accomplishes this using libraries such as `pandas`, `numpy`, `scikit-learn`, and `tensorflow`.\n",
       "\n",
       "Make sure you have the necessary libraries installed. You can install them using pip if you haven't done so already:\n",
       "\n",
       "```bash\n",
       "pip install pandas numpy scikit-learn tensorflow imbalanced-learn\n",
       "```\n",
       "\n",
       "Here’s the complete code:\n",
       "\n",
       "```python\n",
       "import pandas as pd\n",
       "import numpy as np\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.impute import KNNImputer\n",
       "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
       "from sklearn.compose import ColumnTransformer\n",
       "from sklearn.pipeline import Pipeline\n",
       "from sklearn.ensemble import IsolationForest\n",
       "from sklearn.utils import resample\n",
       "from tensorflow import keras\n",
       "from tensorflow.keras import layers\n",
       "\n",
       "# Load the Titanic dataset\n",
       "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
       "data = pd.read_csv(url)\n",
       "\n",
       "# Display the first few rows of the dataset\n",
       "print(data.head())\n",
       "\n",
       "# Step 1: Preprocessing\n",
       "# Drop columns that won't be used\n",
       "data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
       "\n",
       "# Step 2: Missing value treatment using KNN Imputation\n",
       "# Identify categorical and numerical columns\n",
       "categorical_cols = ['Sex', 'Embarked']\n",
       "numerical_cols = ['Age', 'Fare', 'SibSp', 'Parch']\n",
       "\n",
       "# Create a KNN Imputer\n",
       "imputer = KNNImputer(n_neighbors=5)\n",
       "\n",
       "# Impute missing values\n",
       "data[numerical_cols] = imputer.fit_transform(data[numerical_cols])\n",
       "\n",
       "# Step 3: Encoding categorical variables\n",
       "# One-hot encoding for categorical features\n",
       "data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
       "\n",
       "# Step 4: Feature scaling\n",
       "scaler = StandardScaler()\n",
       "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
       "\n",
       "# Step 5: Outlier treatment using Isolation Forest\n",
       "iso_forest = IsolationForest(contamination=0.05)\n",
       "outliers = iso_forest.fit_predict(data)\n",
       "data = data[outliers != -1]\n",
       "\n",
       "# Step 6: Imbalance treatment using resampling\n",
       "X = data.drop('Survived', axis=1)\n",
       "y = data['Survived']\n",
       "\n",
       "# Separate majority and minority classes\n",
       "X_majority = X[y == 0]\n",
       "y_majority = y[y == 0]\n",
       "X_minority = X[y == 1]\n",
       "y_minority = y[y == 1]\n",
       "\n",
       "# Upsample minority class\n",
       "X_minority_upsampled, y_minority_upsampled = resample(X_minority, y_minority,\n",
       "                                                       replace=True,     # sample with replacement\n",
       "                                                       n_samples=len(y_majority),    # to match majority class\n",
       "                                                       random_state=123) # reproducible results\n",
       "\n",
       "# Combine majority class with upsampled minority class\n",
       "X_balanced = pd.concat([X_majority, X_minority_upsampled])\n",
       "y_balanced = pd.concat([y_majority, y_minority_upsampled])\n",
       "\n",
       "# Step 7: Train-test split\n",
       "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
       "\n",
       "# Step 8: Build the MLP model\n",
       "model = keras.Sequential([\n",
       "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
       "    layers.Dense(32, activation='relu'),\n",
       "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
       "])\n",
       "\n",
       "# Compile the model\n",
       "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
       "\n",
       "# Step 9: Train the model\n",
       "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
       "\n",
       "# Step 10: Evaluate the model\n",
       "loss, accuracy = model.evaluate(X_test, y_test)\n",
       "print(f'Test Accuracy: {accuracy:.4f}')\n",
       "```\n",
       "\n",
       "### Explanation of the Code:\n",
       "1. **Data Loading**: The Titanic dataset is loaded from a URL.\n",
       "2. **Preprocessing**:\n",
       "   - Unnecessary columns are dropped.\n",
       "   - Missing values in numerical columns are treated using KNN imputation.\n",
       "   - Categorical variables are encoded using one-hot encoding.\n",
       "   - Features are scaled using `StandardScaler`.\n",
       "   - Outliers are detected and removed using the Isolation Forest algorithm.\n",
       "   - Class imbalance is addressed by upsampling the minority class.\n",
       "3. **Model Building**: A simple MLP model is created using Keras with two hidden layers.\n",
       "4. **Training and Evaluation**: The model is trained on the training set and evaluated on the test set.\n",
       "\n",
       "Make sure to adjust the parameters and architecture of the model as needed based on your specific requirements and dataset characteristics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt =f\"\"\"\n",
    "Act as an expert in generating python code.\n",
    "\n",
    "Your task is to generate python code to build a \"supervised maching learning by using Deep Neural Network (MLP)\" for\n",
    "Titanic Dataset by openai python library.\n",
    "please note to do preprocessing extensively basis below instruction and post then build MultiLayer Perceptron Model-\n",
    "1) missing value treatement by using knn imputation\n",
    "2) encoding 3) Feature scaling 4) outlier treatement 5) imbalance treatement \n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d297e87-592e-4e89-8e7f-9a46829ff74e",
   "metadata": {},
   "source": [
    "# Task 4 - Coding Tasks - SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62c91270-cfdb-40ff-b53c-532ed36e14d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To retrieve the employee with the maximum salary in the 'IT' department, you can use a SQL query that joins the `employees`, `salaries`, and `departments` tables. Here’s how you can construct the query:\n",
       "\n",
       "```sql\n",
       "SELECT e.EmpID, e.EmpName, s.Salary\n",
       "FROM employees e\n",
       "JOIN salaries s ON e.EmpID = s.EmpID\n",
       "JOIN departments d ON e.DepName = d.DepName\n",
       "WHERE d.DepName = 'IT'\n",
       "ORDER BY s.Salary DESC\n",
       "LIMIT 1;\n",
       "```\n",
       "\n",
       "### Explanation:\n",
       "1. **SELECT**: We select the employee ID, employee name, and salary.\n",
       "2. **FROM**: We start from the `employees` table (aliased as `e`).\n",
       "3. **JOIN**: We join the `salaries` table (aliased as `s`) on the `EmpID` to get the salary information. We also join the `departments` table (aliased as `d`) on the `DepName` to filter by department.\n",
       "4. **WHERE**: We filter the results to only include employees in the 'IT' department.\n",
       "5. **ORDER BY**: We order the results by salary in descending order to get the highest salary first.\n",
       "6. **LIMIT 1**: We limit the results to just one record, which will be the employee with the maximum salary in the 'IT' department.\n",
       "\n",
       "This query will return the employee with the highest salary in the specified department."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as an expert in generating SQL code.\n",
    "\n",
    "understanding the following schema of the database tables carefully.\n",
    "Table departments, columns = [DepID, DepName]\n",
    "Table employees, columns = [EmpID, EmpName, DepName]\n",
    "Table salaries, columns = [EmpID, Salary]\n",
    "\n",
    "create a MySQL query for the employee with max salary in the 'IT' Department.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eddb293f-d52b-4aac-bc37-e12ab3090818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To create a Proc SQL query in SAS that retrieves the employee with the maximum salary in the 'IT' department, you can follow these steps:\n",
       "\n",
       "1. Join the `employees` table with the `salaries` table to get the salary information for each employee.\n",
       "2. Filter the results to include only those employees who belong to the 'IT' department.\n",
       "3. Use the `MAX` function to find the maximum salary and then retrieve the corresponding employee details.\n",
       "\n",
       "Here is the SAS Proc SQL code to achieve this:\n",
       "\n",
       "```sas\n",
       "proc sql;\n",
       "    select e.EmpID, e.EmpName, s.Salary\n",
       "    from employees e\n",
       "    join salaries s on e.EmpID = s.EmpID\n",
       "    where e.DepName = 'IT'\n",
       "    and s.Salary = (select max(Salary) \n",
       "                    from salaries s2 \n",
       "                    join employees e2 on s2.EmpID = e2.EmpID \n",
       "                    where e2.DepName = 'IT')\n",
       "    ;\n",
       "quit;\n",
       "```\n",
       "\n",
       "### Explanation:\n",
       "- The `select` statement retrieves the employee ID, employee name, and salary.\n",
       "- The `from` clause specifies the `employees` table (aliased as `e`) and joins it with the `salaries` table (aliased as `s`) on the `EmpID`.\n",
       "- The `where` clause filters the results to include only employees in the 'IT' department.\n",
       "- The subquery `(select max(Salary) ...)` finds the maximum salary for employees in the 'IT' department, ensuring that only the employee(s) with that maximum salary are returned.\n",
       "\n",
       "This query will return the employee(s) with the highest salary in the 'IT' department. If there are multiple employees with the same maximum salary, all of them will be included in the result."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as an expert in generating SQL code.\n",
    "\n",
    "understanding the following schema of the database tables carefully.\n",
    "Table departments, columns = [DepID, DepName]\n",
    "Table employees, columns = [EmpID, EmpName, DepName]\n",
    "Table salaries, columns = [EmpID, Salary]\n",
    "\n",
    "create a ProcSQL query in SAS for the employee with max salary in the 'IT' Department.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2ff51c-4947-4a6e-8dda-8025f353272e",
   "metadata": {},
   "source": [
    "# Task 5 - Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3645d6f1-39cc-47b8-84b2-927c690ffa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_note = \"\"\"\n",
    "60-year-old man in NAD with a h/o CAD, DM2, asthma, pharyngitis, SBP,\n",
    "and HTN on altace for 8 years awoke from sleep around 1:00 am this morning\n",
    "with a sore throat and swelling of the tongue.\n",
    "He came immediately to the ED because he was having difficulty swallowing and\n",
    "some trouble breathing due to obstruction caused by the swelling.\n",
    "He did not have any associated SOB, chest pain, itching, or nausea.\n",
    "He has not noticed any rashes.\n",
    "He says that he feels like it is swollen down in his esophagus as well.\n",
    "He does not recall vomiting but says he might have retched a bit.\n",
    "In the ED he was given 25mg benadryl IV, 125 mg solumedrol IV,\n",
    "and pepcid 20 mg IV.\n",
    "Family history of CHF and esophageal cancer (father).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "243ac82d-bdac-4c47-a3ac-cde4d5ffb94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the extracted information from the clinical note regarding symptoms:\n",
       "\n",
       "| Symptoms                                   | Present/Denies | Probability |\n",
       "|--------------------------------------------|----------------|-------------|\n",
       "| Sore throat                                | Present        | High        |\n",
       "| Swelling of the tongue                     | Present        | High        |\n",
       "| Difficulty swallowing                       | Present        | High        |\n",
       "| Trouble breathing                           | Present        | High        |\n",
       "| Shortness of breath                         | Denies         | High        |\n",
       "| Chest pain                                 | Denies         | High        |\n",
       "| Itching                                    | Denies         | High        |\n",
       "| Nausea                                     | Denies         | High        |\n",
       "| Rashes                                      | Denies         | High        |\n",
       "| Swelling in the esophagus                  | Present        | Medium      |\n",
       "| Vomiting                                   | Denies         | Medium      |\n",
       "| Retching                                   | Present        | Medium      |\n",
       "\n",
       "### Note on Probabilities:\n",
       "- **High Probability**: Symptoms such as sore throat, swelling of the tongue, difficulty swallowing, trouble breathing, and the absence of shortness of breath, chest pain, itching, nausea, and rashes are clearly stated in the clinical note. The language used is definitive, indicating a strong presence or absence of these symptoms.\n",
       "- **Medium Probability**: The swelling in the esophagus and retching are mentioned but are less definitive. The patient expresses a feeling of swelling in the esophagus, which is subjective and not directly observed. Retching is mentioned as a possibility rather than a certainty, leading to a medium probability rating.\n",
       "\n",
       "### Appendix Table\n",
       "\n",
       "| Acronym          | Expanded Form                     |\n",
       "|------------------|-----------------------------------|\n",
       "| NAD              | No Acute Distress                 |\n",
       "| h/o              | History of                        |\n",
       "| CAD              | Coronary Artery Disease           |\n",
       "| DM2              | Diabetes Mellitus Type 2         |\n",
       "| SBP              | Systolic Blood Pressure           |\n",
       "| HTN              | Hypertension                      |\n",
       "| IV               | Intravenous                       |\n",
       "| CHF              | Congestive Heart Failure          | \n",
       "| esophageal cancer | Esophageal Cancer                 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Act as an expert in analyzing and understanding clinical doctor notes in healthcare.\n",
    "Extract all symptoms only from the clinical note information below.\n",
    "Differentiate between symptoms that are present vs. absent.\n",
    "Give me the probability (high/ medium/ low) of how sure you are about the result.\n",
    "Add a note on the probabilities and why you think so.\n",
    "\n",
    "Output as a markdown table with the following columns,\n",
    "all symptoms should be expanded and no acronyms unless you don't know:\n",
    "\n",
    "Symptoms | Present/Denies | Probability.\n",
    "\n",
    "Also expand all acronyms.\n",
    "Output that also as a separate appendix table in Markdown.\n",
    "\n",
    "Clinical Note:\n",
    "```{clinical_note}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a95f25-fa94-4d40-aae6-3a9a2af41a99",
   "metadata": {},
   "source": [
    "# Task - 6 : Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db6b5c42-8419-4263-9d11-cd12b086db3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the translations of the provided text into the requested languages:\n",
       "\n",
       "**German:**\n",
       "Betreff: Antrag auf Krankheitsurlaub für [Urlaubsdaten]\n",
       "Sehr geehrter Manager,\n",
       "ich fühle mich unwohl und möchte für [Urlaubsdaten] Krankheitsurlaub beantragen. Ich werde sicherstellen, dass ich alle ausstehenden Aufgaben erledige, sobald ich zurück bin, und Sie informieren, falls es Änderungen gibt.\n",
       "Bitte lassen Sie mich wissen, ob Sie weitere Informationen benötigen.\n",
       "\n",
       "**Spanish:**\n",
       "Asunto: Solicitud de licencia por enfermedad del [Fechas de licencia]\n",
       "Estimado/a Gerente,\n",
       "me siento mal y me gustaría solicitar una licencia por enfermedad del [Fechas de licencia]. Me aseguraré de completar cualquier tarea pendiente una vez que regrese y le mantendré informado/a si hay algún cambio.\n",
       "Por favor, hágame saber si necesita más información.\n",
       "\n",
       "**Hindi:**\n",
       "विषय: [अवकाश तिथियों] पर बीमार छुट्टी के लिए अनुरोध\n",
       "प्रिय प्रबंधक,\n",
       "मैं अस्वस्थ महसूस कर रहा हूँ और [अवकाश तिथियों] के लिए बीमार छुट्टी का अनुरोध करना चाहता हूँ। मैं सुनिश्चित करूंगा कि लौटने के बाद कोई भी लंबित कार्य पूरा कर दूं और यदि कोई परिवर्तन होता है तो आपको अपडेट रखूंगा।\n",
       "कृपया मुझे बताएं कि क्या आपको किसी और जानकारी की आवश्यकता है।\n",
       "\n",
       "**Tamil:**\n",
       "หัวข้อ: [விடுமுறை தேதிகள்] இல் நோய்வாய்ப்பு விடுமுறை கோரிக்கை\n",
       "அன்புள்ள மேலாளர்,\n",
       "நான் உடல் நலக்குறைவால் பாதிக்கப்படுகிறேன் மற்றும் [விடுமுறை தேதிகள்] இல் நோய்வாய்ப்பு விடுமுறை கோர விரும்புகிறேன். நான் திரும்பிய பிறகு எந்தவொரு நிலுவையில் உள்ள பணிகளையும் முடிக்க உறுதி செய்கிறேன் மற்றும் எந்த மாற்றங்களும் இருந்தால் உங்களை புதுப்பிக்கிறேன்.\n",
       "மேலும் தகவலுக்கு நீங்கள் என்னை தொடர்பு கொள்ளவும்.\n",
       "\n",
       "**Telugu:**\n",
       "విషయం: [విడుదల తేదీలు] పై రోగ సెలవు కోసం అభ్యర్థన\n",
       "ప్రియమైన మేనేజర్,\n",
       "నేను ఆరోగ్యంగా లేను మరియు [విడుదల తేదీలు] కోసం రోగ సెలవు కోరుతున్నాను. నేను తిరిగి వచ్చిన తర్వాత ఎలాంటి పెండింగ్ పనులను పూర్తి చేస్తాను మరియు మార్పులు ఉంటే మీకు సమాచారం అందిస్తాను.\n",
       "మీకు మరింత సమాచారం అవసరమైతే దయచేసి నాకు తెలియజేయండి.\n",
       "\n",
       "**Gujarati:**\n",
       "વિષય: [છુટ્ટા તારીખો] પર બીમારીની રજા માટે વિનંતી\n",
       "પ્રિય મેનેજર,\n",
       "હું અસ્વસ્થ અનુભવી રહ્યો છું અને [છુટ્ટા તારીખો] માટે બીમારીની રજા માંગું છું. હું પાછા ફર્યા પછી કોઈપણ બાકી કામ પૂર્ણ કરવા ખાતરી આપીશ અને જો કોઈ ફેરફાર થાય તો તમને અપડેટ રાખીશ.\n",
       "કૃપા કરીને મને જણાવો કે શું તમને વધુ માહિતીની જરૂર છે.\n",
       "\n",
       "**Marathi:**\n",
       "विषय: [अवकाश तारीख] वर आजारी सुट्टीसाठी विनंती\n",
       "प्रिय व्यवस्थापक,\n",
       "मी अस्वस्थ आहे आणि [अवकाश तारीख] साठी आजारी सुट्टीची विनंती करतो. मी परत आल्यानंतर कोणतीही प्रलंबित कामे पूर्ण करण्याची खात्री करतो आणि कोणतेही बदल झाल्यास तुम्हाला अपडेट ठेवतो.\n",
       "कृपया तुम्हाला आणखी माहिती हवी असल्यास मला कळवा.\n",
       "\n",
       "**Bengali:**\n",
       "বিষয়: [ছুটির তারিখ] এ অসুস্থ ছুটির জন্য আবেদন\n",
       "প্রিয় ম্যানেজার,\n",
       "আমি অসুস্থ অনুভব করছি এবং [ছুটির তারিখ] এ অসুস্থ ছুটির জন্য আবেদন করতে চাই। আমি ফিরে আসার পর যে কোনও বাকি কাজ সম্পন্ন করার নিশ্চয়তা দেব এবং যদি কোনও পরিবর্তন হয় তবে আপনাকে আপডেট রাখব।\n",
       "আপনার যদি আরও তথ্যের প্রয়োজন হয় তবে দয়া করে আমাকে জানান।\n",
       "\n",
       "**Tulu:**\n",
       "ವಿಷಯ: [ಊರ ದಿನಾಂಕಗಳು] ರೋಗಾವಸ್ಥೆ ರಜೆಗೆ ವಿನಂತಿ\n",
       "ಪ್ರಿಯ ಮ್ಯಾನೇಜರ್,\n",
       "ನಾನು ಆರೋಗ್ಯವಾಗಿಲ್ಲ ಮತ್ತು [ಊರ ದಿನಾಂಕಗಳು] ರೋಗಾವಸ್ಥೆ ರಜೆಗೆ ವಿನಂತಿ ಮಾಡುತ್ತೇನೆ. ನಾನು ಹಿಂದಿರುಗಿದ ನಂತರ ಯಾವುದೇ ಬಾಕಿ ಕೆಲಸಗಳನ್ನು ಪೂರ್ಣಗೊಳಿಸಲು ಖಚಿತಪಡಿಸುತ್ತೇನೆ ಮತ್ತು ಯಾವುದೇ ಬದಲಾವಣೆಗಳಿದ್ದರೆ ನಿಮಗೆ ಮಾಹಿತಿ ನೀಡುತ್ತೇನೆ.\n",
       "ನಿಮಗೆ ಇನ್ನಷ್ಟು ಮಾಹಿತಿಯ ಅಗತ್ಯವಿದ್ದರೆ ದಯವಿಟ್ಟು ನನಗೆ ತಿಳಿಸಿ.\n",
       "\n",
       "**Odia:**\n",
       "ବିଷୟ: [ଛୁଟି ତାରିଖ] ରେ ରୋଗ ଛୁଟି ପାଇଁ ଅନୁରୋଧ\n",
       "ପ୍ରିୟ ମ୍ୟାନେଜର,\n",
       "ମୁଁ ଅସୁସ୍ଥ ଅନୁଭବ କରୁଛି ଏବଂ [ଛୁଟି ତାରିଖ] ରେ ରୋଗ ଛୁଟି ପାଇଁ ଅନୁରୋଧ କରୁଛି। ମୁଁ ଫେରିବା ପରେ କୌଣସି ବକି ତାଲିକା କାମ ସମ୍ପୂର୍ଣ୍ଣ କରିବାକୁ ନିଶ୍ଚିତ କରିବି ଏବଂ ଯଦି କୌଣସି ପରିବର୍ତ୍ତନ ହୁଏ ତେବେ ଆପଣଙ୍କୁ ଅପଡେଟ୍ ରଖିବି।\n",
       "ଦୟାକରି ଆପଣଙ୍କୁ ଅଧିକ ସୂଚନା ଆବଶ୍ୟକ ହେଲେ ମୋତେ ଜଣାଇବେ।\n",
       "\n",
       "**Maithili:**\n",
       "विषय: [छुट्टी के तिथि] पर बीमार छुट्टी के लिए अनुरोध\n",
       "प्रिय प्रबंधक,\n",
       "हम अस्वस्थ महसूस कर रहल छी और [छुट्टी के तिथि] पर बीमार छुट्टी के लिए अनुरोध कर रहल छी। हम लौटने के बाद कोई भी लंबित कार्य पूरा करब और यदि कोई परिवर्तन होए त हम अपने के अपडेट रखब।\n",
       "कृपया बताउ कि यदि अपने के और जानकारी के आवश्यकता अछि।\n",
       "\n",
       "**Malayalam:**\n",
       "വിഷയം: [അവധിയുടെ തീയതികൾ] നുള്ള രോഗ അവധിക്ക് അപേക്ഷ\n",
       "പ്രിയ മാനേജർ,\n",
       "ഞാൻ അസുഖം അനുഭവിക്കുന്നു, [അവധിയുടെ തീയതികൾ] നുള്ള രോഗ അവധിക്ക് അപേക്ഷിക്കാനാണ് ആഗ്രഹിക്കുന്നത്. ഞാൻ തിരികെ വന്ന ശേഷം ബാക്കി ഉള്ള എല്ലാ ജോലികളും പൂർത്തിയാക്കാൻ ഉറപ്പുനൽകുന്നു, കൂടാതെ മാറ്റങ്ങൾ ഉണ്ടെങ്കിൽ നിങ്ങളെ അപ്ഡേറ്റ് ചെയ്യാൻ ഞാൻ ശ്രമിക്കും.\n",
       "കൂടുതൽ വിവരങ്ങൾ ആവശ്യമുണ്ടെങ്കിൽ ദയവായി എന്നെ അറിയിക്കുക.\n",
       "\n",
       "**Kannada:**\n",
       "ವಿಷಯ: [ಅವಕಾಶ ದಿನಾಂಕಗಳು] ರೋಗ ರಜೆಗೆ ವಿನಂತಿ\n",
       "ಪ್ರಿಯ ಮ್ಯಾನೇಜರ್,\n",
       "ನಾನು ಆರೋಗ್ಯವಾಗಿಲ್ಲ ಮತ್ತು [ಅವಕಾಶ ದಿನಾಂಕಗಳು] ರೋಗ ರಜೆಗೆ ವಿನಂತಿ ಮಾಡುತ್ತೇನೆ. ನಾನು ಹಿಂದಿರುಗಿದ ನಂತರ ಯಾವುದೇ ಬಾಕಿ ಕೆಲಸಗಳನ್ನು ಪೂರ್ಣಗೊಳಿಸಲು ಖಚಿತಪಡಿಸುತ್ತೇನೆ ಮತ್ತು ಯಾವುದೇ ಬದಲಾವಣೆಗಳಿದ್ದರೆ ನಿಮಗೆ ಮಾಹಿತಿ ನೀಡುತ್ತೇನೆ.\n",
       "ನಿಮಗೆ ಇನ್ನಷ್ಟು ಮಾಹಿತಿಯ ಅಗತ್ಯವಿದ್ದರೆ ದಯವಿಟ್ಟು ನನಗೆ ತಿಳಿಸಿ.\n",
       "\n",
       "**Punjabi:**\n",
       "ਵਿਸ਼ਾ: [ਛੁੱਟੀ ਦੀਆਂ ਤਾਰੀਖਾਂ] 'ਤੇ ਬਿਮਾਰੀ ਦੀ ਛੁੱਟੀ ਲਈ ਬੇਨਤੀ\n",
       "ਪਿਆਰੇ ਮੈਨੇਜਰ,\n",
       "ਮੈਂ ਅਸੁਥ ਹੋ ਰਿਹਾ ਹਾਂ ਅਤੇ [ਛੁੱਟੀ ਦੀਆਂ ਤਾਰੀਖਾਂ] ਲਈ ਬਿਮਾਰੀ ਦੀ ਛੁੱਟੀ ਦੀ ਬੇਨਤੀ ਕਰਨਾ ਚਾਹੁੰਦਾ ਹਾਂ। ਮੈਂ ਵਾਪਸ ਆਉਣ 'ਤੇ ਕਿਸੇ ਵੀ ਬਾਕੀ ਕੰਮ ਨੂੰ ਪੂਰਾ ਕਰਨ ਦੀ ਯਕੀਨੀ ਬਣਾਵਾਂਗਾ ਅਤੇ ਜੇ ਕੋਈ ਬਦਲਾਅ ਹੋਵੇ ਤਾਂ ਤੁਹਾਨੂੰ ਅਪਡੇਟ ਰੱਖਾਂਗਾ।\n",
       "ਕਿਰਪਾ ਕਰਕੇ ਮੈਨੂੰ ਦੱਸੋ ਕਿ ਕੀ ਤੁਹਾਨੂੰ ਹੋਰ ਜਾਣਕਾਰੀ ਦੀ ਲੋੜ ਹੈ।\n",
       "\n",
       "**Nepali:**\n",
       "विषय: [छुट्टीको मिति] मा बिरामी बिदाको लागि अनुरोध\n",
       "प्रिय प्रबन्धक,\n",
       "म अस्वस्थ महसुस गर्दैछु र [छुट्टीको मिति] मा बिरामी बिदाको लागि अनुरोध गर्न चाहन्छु। म फर्केपछि कुनै पनि बाँकी काम पूरा गर्ने सुनिश्चित गर्नेछु र यदि कुनै परिवर्तन भएमा तपाईंलाई अपडेट राख्नेछु।\n",
       "कृपया मलाई बताउनुहोस् कि यदि तपाईंलाई थप जानकारीको आवश्यकता छ भने। \n",
       "\n",
       "Feel free to ask if you need any further assistance!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"You are an expert translator. Translate the given text from English to German, Spanish, Hindi, Tamil, Telgu, \n",
    "Gujarati, Marathi, Bengali, tulu, oriya, maithili, malayalam,kannada,punjabi, and nepali.\n",
    "\n",
    "Text:\"Subject: Request for Sick Leave on [Leave Dates]\n",
    "Dear Manager,\n",
    "I am feeling unwell and would like to request sick leave for [Leave Dates]. I will ensure to complete any pending tasks once I return and keep you updated if there are any changes.\n",
    "Please let me know if you need any further information.\"\n",
    "\n",
    "Transaltion:\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11b1ad22-d01b-4ebd-a67e-fd78c4738e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the translations for \"Hi, how are you\" in the requested languages:\n",
       "\n",
       "- **German**: \"Hallo, wie geht es dir?\"\n",
       "- **Spanish**: \"Hola, ¿cómo estás?\"\n",
       "- **Hindi**: \"नमस्ते, आप कैसे हैं?\"\n",
       "- **Tamil**: \"வணக்கம், நீங்கள் எப்படி இருக்கிறீர்கள்?\"\n",
       "- **Telugu**: \"హాయ్, మీరు ఎలా ఉన్నారు?\"\n",
       "- **Gujarati**: \"હાય, તમે કેમ છો?\"\n",
       "- **Marathi**: \"नमस्कार, तुम्ही कसे आहात?\"\n",
       "- **Bengali**: \"হ্যালো, তুমি কেমন আছো?\"\n",
       "- **Tulu**: \"ನಮಸ್ಕಾರ, ನಿನಗೆ ಹೇಗಿದೆ?\"\n",
       "- **Oriya**: \"ନମସ୍କାର, ତୁମେ କେମିତି ଅଛ?\"\n",
       "- **Maithili**: \"नमस्कार, अहाँ केहन छी?\"\n",
       "- **Malayalam**: \"ഹായ്, നീ എങ്ങനെയുണ്ട്?\"\n",
       "- **Kannada**: \"ಹಾಯ್, ನೀವು ಹೇಗಿದ್ದೀರಿ?\"\n",
       "- **Punjabi**: \"ਸਤ ਸ੍ਰੀ ਅਕਾਲ, ਤੁਸੀਂ ਕਿਵੇਂ ਹੋ?\"\n",
       "- **Nepali**: \"नमस्ते, तपाईँलाई कस्तो छ?\"\n",
       "\n",
       "If you need any further assistance, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"You are an expert translator. Translate the given text from English to German, Spanish, Hindi, Tamil, Telgu, \n",
    "Gujarati, Marathi, Bengali, tulu, oriya, maithili, malayalam,kannada,punjabi, and nepali.\n",
    "\n",
    "Text:\"Hi, how are you\"\n",
    "\n",
    "Transaltion:\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c93e8-0a7e-4fe0-8ce7-abbfd311a9e6",
   "metadata": {},
   "source": [
    "# Task 7 - Document Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b9c79a8b-3a9d-4345-82be-b8ee71d72f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"\n",
    "Coronaviruses are a large family of viruses which may cause illness in animals or humans.\n",
    "In humans, several coronaviruses are known to cause respiratory infections ranging from the\n",
    "common cold to more severe diseases such as Middle East Respiratory Syndrome (MERS) and Severe Acute Respiratory Syndrome (SARS).\n",
    "The most recently discovered coronavirus causes coronavirus disease COVID-19.\n",
    "COVID-19 is the infectious disease caused by the most recently discovered coronavirus.\n",
    "This new virus and disease were unknown before the outbreak began in Wuhan, China, in December 2019.\n",
    "COVID-19 is now a pandemic affecting many countries globally.\n",
    "The most common symptoms of COVID-19 are fever, dry cough, and tiredness.\n",
    "Other symptoms that are less common and may affect some patients include aches\n",
    "and pains, nasal congestion, headache, conjunctivitis, sore throat, diarrhea,\n",
    "loss of taste or smell or a rash on skin or discoloration of fingers or toes.\n",
    "These symptoms are usually mild and begin gradually.\n",
    "Some people become infected but only have very mild symptoms.\n",
    "Most people (about 80%) recover from the disease without needing hospital treatment.\n",
    "Around 1 out of every 5 people who gets COVID-19 becomes seriously ill and develops difficulty breathing.\n",
    "Older people, and those with underlying medical problems like high blood pressure, heart and lung problems,\n",
    "diabetes, or cancer, are at higher risk of developing serious illness.\n",
    "However, anyone can catch COVID-19 and become seriously ill.\n",
    "People of all ages who experience fever and/or  cough associated with difficulty breathing/shortness of breath,\n",
    "chest pain/pressure, or loss of speech or movement should seek medical attention immediately.\n",
    "If possible, it is recommended to call the health care provider or facility first,\n",
    "so the patient can be directed to the right clinic.\n",
    "People can catch COVID-19 from others who have the virus.\n",
    "The disease spreads primarily from person to person through small droplets from the nose or mouth,\n",
    "which are expelled when a person with COVID-19 coughs, sneezes, or speaks.\n",
    "These droplets are relatively heavy, do not travel far and quickly sink to the ground.\n",
    "People can catch COVID-19 if they breathe in these droplets from a person infected with the virus.\n",
    "This is why it is important to stay at least 1 meter) away from others.\n",
    "These droplets can land on objects and surfaces around the person such as tables, doorknobs and handrails.\n",
    "People can become infected by touching these objects or surfaces, then touching their eyes, nose or mouth.\n",
    "This is why it is important to wash your hands regularly with soap and water or clean with alcohol-based hand rub.\n",
    "Practicing hand and respiratory hygiene is important at ALL times and is the best way to protect others and yourself.\n",
    "When possible maintain at least a 1 meter distance between yourself and others.\n",
    "This is especially important if you are standing by someone who is coughing or sneezing.\n",
    "Since some infected persons may not yet be exhibiting symptoms or their symptoms may be mild,\n",
    "maintaining a physical distance with everyone is a good idea if you are in an area where COVID-19 is circulating.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d7a91e4e-7bdc-4577-a7fd-bfb1a0f4f86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "SUMMARY: Coronaviruses can cause respiratory infections in humans, with COVID-19 being the most recent and severe outbreak, first identified in Wuhan, China, in December 2019. Common symptoms include fever, cough, and tiredness, while serious cases can lead to difficulty breathing, especially in older adults and those with underlying health issues. The virus spreads primarily through respiratory droplets, making physical distancing and hand hygiene crucial for prevention. Most people recover without hospitalization, but immediate medical attention is advised for severe symptoms."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are an expert in generating accurate document summaries.\n",
    "Generate a summary of the given document.\n",
    "\n",
    "Document:\n",
    "{doc}\n",
    "\n",
    "constraints: Please start the summary with the delimiter \"SUMMARY :\" and limit the summary to 5 lines only\n",
    "\n",
    "SUMMARY:\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "783b32ad-ac9b-485f-9ecd-0ddcecf6f55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBy calling for an all-party meeting on March 5 to discuss the delimitation exercise, Tamil Nadu Chief Minister M.K. Stalin has sought to stir up a national debate. Delimitation, as an exercise, has not seen any increase in the legislative seats since 1973, having been frozen as per the 1971 Census for parity in population growth across States. This was done to prevent States with a higher population growth from getting “rewarded” with a higher number of representatives at the cost of other States with better health indices and lower growth. The 84th constitutional Amendment had stipulated that the delimitation exercise would be based on the first Census after 2026. Is the Union government inexplicably delaying the Census exercise to allow for the delimitation exercise to be held earlier? In the normal scheme of things, the exercise would have been done after the 2031 Census, but it is now possible after 2026 once the Census (due in 2021), is conducted.\\nThe concern of Tamil Nadu that the exercise could hurt its representation in Parliament is legitimate if the Centre intends the process to be only proportionally representative of each State’s population. This is illustrated in the population growth rates (1971-2024) in Tamil Nadu and undivided Bihar. The electorate, for which recent data is available, grew by 171% in the former as against 233% in the latter, while they had a comparable number of Lok Sabha MPs (39 versus 54, including Jharkhand). If delimitation was held and constituencies redrawn to match population growth, and even if the overall Lok Sabha tally was increased, the final number for Tamil Nadu would clearly be much lower than Bihar’s. Other States with reduced fertility rates, such as Kerala and Karnataka, will also be affected. Home Minister Amit Shah has said that there will be no “reduction on a pro-rata basis” for Southern States and that they would get their “rightful share” but there has been little clarity on whether this would mean that their proportion of representatives will be retained after delimitation. The significant increase in population since 1973 should lead to an increased number of representatives, and, therefore, a higher number of seats, especially in north India’s highly populated States. Yet, the equally important principle of federalism should suggest the need for the proportions of representation to be maintained to keep the balance of power intact across States. More importantly, the government must expedite the Census just to allay concerns that it has been delayed to facilitate an earlier and controversial delimitation. A nation striving to reach the higher pedestals of world power cannot afford to delay the basic exercise of counting the number of its own people.\\n\\n\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editorial = f\"\"\"\n",
    "By calling for an all-party meeting on March 5 to discuss the delimitation exercise, Tamil Nadu Chief Minister M.K. Stalin has sought to stir up a national debate. Delimitation, as an exercise, has not seen any increase in the legislative seats since 1973, having been frozen as per the 1971 Census for parity in population growth across States. This was done to prevent States with a higher population growth from getting “rewarded” with a higher number of representatives at the cost of other States with better health indices and lower growth. The 84th constitutional Amendment had stipulated that the delimitation exercise would be based on the first Census after 2026. Is the Union government inexplicably delaying the Census exercise to allow for the delimitation exercise to be held earlier? In the normal scheme of things, the exercise would have been done after the 2031 Census, but it is now possible after 2026 once the Census (due in 2021), is conducted.\n",
    "The concern of Tamil Nadu that the exercise could hurt its representation in Parliament is legitimate if the Centre intends the process to be only proportionally representative of each State’s population. This is illustrated in the population growth rates (1971-2024) in Tamil Nadu and undivided Bihar. The electorate, for which recent data is available, grew by 171% in the former as against 233% in the latter, while they had a comparable number of Lok Sabha MPs (39 versus 54, including Jharkhand). If delimitation was held and constituencies redrawn to match population growth, and even if the overall Lok Sabha tally was increased, the final number for Tamil Nadu would clearly be much lower than Bihar’s. Other States with reduced fertility rates, such as Kerala and Karnataka, will also be affected. Home Minister Amit Shah has said that there will be no “reduction on a pro-rata basis” for Southern States and that they would get their “rightful share” but there has been little clarity on whether this would mean that their proportion of representatives will be retained after delimitation. The significant increase in population since 1973 should lead to an increased number of representatives, and, therefore, a higher number of seats, especially in north India’s highly populated States. Yet, the equally important principle of federalism should suggest the need for the proportions of representation to be maintained to keep the balance of power intact across States. More importantly, the government must expedite the Census just to allay concerns that it has been delayed to facilitate an earlier and controversial delimitation. A nation striving to reach the higher pedestals of world power cannot afford to delay the basic exercise of counting the number of its own people.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "editorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7ab62ed-a5ae-43f2-96d4-2842d81d0a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "SUMMARY: Tamil Nadu Chief Minister M.K. Stalin has called for an all-party meeting on March 5 to discuss the implications of the delimitation exercise, which has not seen an increase in legislative seats since 1973. Concerns arise that the Union government may delay the Census to facilitate earlier delimitation, potentially reducing Tamil Nadu's parliamentary representation. Home Minister Amit Shah has assured that Southern States will retain their rightful share, but clarity is lacking. The document emphasizes the need for an expedited Census to address these concerns and maintain federal balance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are an expert in generating accurate document summaries.\n",
    "Generate a summary of the given document.\n",
    "\n",
    "Document:\n",
    "{editorial}\n",
    "\n",
    "constraints: Please start the summary with the delimiter \"SUMMARY :\" and limit the summary to 5 lines only\n",
    "\n",
    "SUMMARY:\n",
    "\"\"\"\n",
    "response = get_completion(prompt, model=\"gpt-4o-mini\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98b615-44a2-46ff-8899-f35968269bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e5e49-b593-4190-9dcf-35c13c0dfd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b672142b-a277-4064-a501-78122bbd5378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda775f-0b97-4ed5-a8f5-7c2b1f4c7b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af3530-fe5d-444e-ac8f-4bc6379961f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
